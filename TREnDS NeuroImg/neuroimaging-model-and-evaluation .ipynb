{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.01042,
     "end_time": "2020-08-21T11:38:20.597629",
     "exception": false,
     "start_time": "2020-08-21T11:38:20.587209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TReNDS NeuroImaging\n",
    "Prediction of multiple assessments plus age from multimodal brain MRI features using image analysis from IR representation of all the corresponding spatial maps. This notebook is for model setup, training and evaluation/prediction. \n",
    "<br>\n",
    "<br>\n",
    "More information about the project is found [here](https://www.kaggle.com/c/trends-assessment-prediction/overview/description)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.010488,
     "end_time": "2020-08-21T11:38:20.617017",
     "exception": false,
     "start_time": "2020-08-21T11:38:20.606529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Score Evaluation\n",
    "The score, $\\mathcal{S}$, is evaluated through the feature-weighted, normalized absolute error defined as\n",
    "\\begin{equation}\n",
    "\\mathcal{S} = \\sum_f w_f \\left(\\frac{\\sum_i \\left|y_{f,i} - \\hat{y}_{f,i}\\right|}{\\sum_i \\hat{y}_{f,i}}\\right),\n",
    "\\end{equation}\n",
    "<br>\n",
    "where $y_{f,i}$ and $\\hat{y}_{f,i}$ is the $i^{th}$ observation and prediction of feature $f$ respectively and the $w_f$ is the weight given to each of the five features with fixed values of\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = \\left[0.3, 0.175, 0.175, 0.175, 0.175\\right]^T,\n",
    "\\end{equation}\n",
    "<br>\n",
    "corresponding to the features $\\mathbf{f} = [\\text{age}, \\text{ domain1_var1}, \\text{ domain1_var2}, \\text{ domain2_var1}, \\text{ domain2_var2}]^T$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008345,
     "end_time": "2020-08-21T11:38:20.633822",
     "exception": false,
     "start_time": "2020-08-21T11:38:20.625477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Explanation\n",
    "The initial model used in this kernel is the [squeezenet](https://arxiv.org/abs/1602.07360) architecture with motivation of its low memory requirement due to less amount of parameters. As concluded in [this paper](https://arxiv.org/pdf/1810.00736.pdf) which analysed benchmarks of representative\n",
    "deep neural network architectures, squeezenet achieved best score of 1% accuracy per million parameters as shown in the figure below![Benchmarks](data:image/jpeg;base64,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)\n",
    "<br>\n",
    "<br>\n",
    "Squeezenets are fully convolutional and uses [Fire modules](https://www.researchgate.net/figure/The-structure-of-the-Fire-module-used-in-SqueezeNet_fig4_328548960) which has a squeeze layer of $1x1$ convolutions that drastically reduce the amount of parameters. This allows them to be trained on more complex image structures than a corresponding depth of another architecture before the local memory is overfilled.\n",
    "<br>\n",
    "<br>\n",
    "**HOWEVER**, the squeezenet performed too poorly in order to be a satisfactory solution to the problem. Therefore, a customized [ResNet](https://arxiv.org/pdf/1512.03385.pdf) was used instead modified in order to fit the hardware limitations. \n",
    "<br>\n",
    "<br>\n",
    "The weights are initialized using [Glorot initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) which samples uniformly from $\\mathcal{U}\\left(-a, a\\right)$ where\n",
    "<br>\n",
    "\\begin{equation}\n",
    "a := \\mathcal{G}\\sqrt{\\frac{6}{n_j+n_{j+1}}},\n",
    "\\end{equation}\n",
    "<br>\n",
    "where $\\mathcal{G}$ is a gain factor that varies depending on the acivation function of the layer/function. For linear and conv layers the gain factor value is set to $\\mathcal{G} = 1$ whereas for the ReLU function the value is set to $\\mathcal{G} = \\sqrt{2}$.\n",
    "<br>\n",
    "<br>\n",
    "Furthermore, during training the learning rate is reduced by $10^{-1}$ after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:20.660740Z",
     "iopub.status.busy": "2020-08-21T11:38:20.660091Z",
     "iopub.status.idle": "2020-08-21T11:38:23.811688Z",
     "shell.execute_reply": "2020-08-21T11:38:23.810419Z"
    },
    "papermill": {
     "duration": 3.169289,
     "end_time": "2020-08-21T11:38:23.811829",
     "exception": false,
     "start_time": "2020-08-21T11:38:20.642540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# General packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import h5py\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "# PyTorch packages\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models, transforms\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008497,
     "end_time": "2020-08-21T11:38:23.829342",
     "exception": false,
     "start_time": "2020-08-21T11:38:23.820845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:23.865876Z",
     "iopub.status.busy": "2020-08-21T11:38:23.864057Z",
     "iopub.status.idle": "2020-08-21T11:38:23.866671Z",
     "shell.execute_reply": "2020-08-21T11:38:23.867132Z"
    },
    "papermill": {
     "duration": 0.029283,
     "end_time": "2020-08-21T11:38:23.867262",
     "exception": false,
     "start_time": "2020-08-21T11:38:23.837979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TReNDSDataset(Dataset):\n",
    "    def __init__(self, data, targets, map_path, train):\n",
    "        self.data = data\n",
    "        self.train = train\n",
    "        self.map_path = map_path\n",
    "        self.map_id = self.data.Id\n",
    "        if train: self.targets = targets\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.map_path + str(self.map_id[idx])\n",
    "        all_maps = h5py.File(path + '.mat', 'r')['SM_feature'][()]\n",
    "        cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n",
    "        \n",
    "        idx_1, idx_2, idx_3 = randint(0, 51), randint(0, 62), randint(0, 52)\n",
    "        proj_1 = cv2.resize(all_maps[:, idx_1, :, :].transpose(1, 2, 0), (config.size, config.size))\n",
    "        proj_2 = cv2.resize(all_maps[:, :, idx_2, :].transpose(1, 2, 0), (config.size, config.size))\n",
    "        proj_3 = cv2.resize(all_maps[:, :, :, idx_3].transpose(1, 2, 0), (config.size, config.size))\n",
    "        features = np.concatenate([proj_1, proj_2, proj_3], axis=2).transpose(2, 0, 1)\n",
    "      \n",
    "        \n",
    "        if not self.train:\n",
    "            return torch.FloatTensor(features)\n",
    "        else:\n",
    "            i = self.map_id[idx]\n",
    "            targets = self.targets.query('Id == {}'.format(i)).values\n",
    "            targets = np.repeat(targets[:, 1:], 159, 0).reshape(-1, 5)\n",
    "            return torch.FloatTensor(features), torch.FloatTensor(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008583,
     "end_time": "2020-08-21T11:38:23.887154",
     "exception": false,
     "start_time": "2020-08-21T11:38:23.878571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:24.262062Z",
     "iopub.status.busy": "2020-08-21T11:38:24.261326Z",
     "iopub.status.idle": "2020-08-21T11:38:24.265378Z",
     "shell.execute_reply": "2020-08-21T11:38:24.266224Z"
    },
    "papermill": {
     "duration": 0.370494,
     "end_time": "2020-08-21T11:38:24.266394",
     "exception": false,
     "start_time": "2020-08-21T11:38:23.895900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cpu')\n",
    "    epochs = 6\n",
    "    dataset_split = 0.8\n",
    "    init_lr = 1e-3\n",
    "    save_path = 'rn_model.pt'\n",
    "    size = 128\n",
    "    batch_size = 32\n",
    "    val_batch_size = 32\n",
    "    num_classes = 5\n",
    "    \n",
    "    base_path = '../input/trends-assessment-prediction/'\n",
    "    train_maps_path = base_path + 'fMRI_train/'\n",
    "    test_maps_path = base_path + 'fMRI_test/'\n",
    "    \n",
    "    feat_path = base_path + 'fnc.csv'\n",
    "    targ_path = base_path + 'train_scores.csv'\n",
    "    submission_path = base_path + 'sample_submission.csv'\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008988,
     "end_time": "2020-08-21T11:38:24.285680",
     "exception": false,
     "start_time": "2020-08-21T11:38:24.276692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simple preprocessing\n",
    "Since the data itself was clean as seen in the visualization kernel, no advanced feature engineering is **necessary**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:24.313226Z",
     "iopub.status.busy": "2020-08-21T11:38:24.312585Z",
     "iopub.status.idle": "2020-08-21T11:38:30.791130Z",
     "shell.execute_reply": "2020-08-21T11:38:30.791689Z"
    },
    "papermill": {
     "duration": 6.496652,
     "end_time": "2020-08-21T11:38:30.791841",
     "exception": false,
     "start_time": "2020-08-21T11:38:24.295189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_Ids = [map_id[:-4] for map_id in sorted(os.listdir(config.test_maps_path))]\n",
    "train_Ids = [map_id[:-4] for map_id in sorted(os.listdir(config.train_maps_path))]\n",
    "\n",
    "targets = pd.read_csv(config.targ_path)\n",
    "targets = targets.fillna(targets.mean())\n",
    "submission_file = pd.read_csv(config.submission_path)\n",
    "\n",
    "features = pd.read_csv(config.feat_path)\n",
    "test_df = features.query('Id in {}'.format(test_Ids)).reset_index(drop=True)\n",
    "train_df = features.query('Id in {}'.format(train_Ids)).reset_index(drop=True)\n",
    "targets.head()\n",
    "print(len(test_Ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009308,
     "end_time": "2020-08-21T11:38:30.810657",
     "exception": false,
     "start_time": "2020-08-21T11:38:30.801349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:30.851667Z",
     "iopub.status.busy": "2020-08-21T11:38:30.835959Z",
     "iopub.status.idle": "2020-08-21T11:38:30.873616Z",
     "shell.execute_reply": "2020-08-21T11:38:30.873140Z"
    },
    "papermill": {
     "duration": 0.054429,
     "end_time": "2020-08-21T11:38:30.873712",
     "exception": false,
     "start_time": "2020-08-21T11:38:30.819283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#### ResNet\n",
    "def conv3(in_channels, out_channels, stride=1, kernel_size=1, padding=0, padding_mode=False):\n",
    "      return (nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding,\n",
    "                       stride=stride, bias=False) if (padding_mode == False) else\n",
    "              (nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                       stride=stride, bias=False, padding_mode=\"replicate\")))\n",
    "\n",
    "  # Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = conv3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3(out_channels, out_channels, kernel_size=1, padding_mode=True)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = conv3(out_channels, out_channels)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=29, channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.in_channels = 32\n",
    "        self.bn = nn.BatchNorm2d(self.channels)\n",
    "        self.conv = conv3(self.channels, 32, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.layer1 = self.make_layer(block, 32, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 64, layers[1])\n",
    "        self.layer3 = self.make_layer(block, 128, layers[2])\n",
    "        self.layer4 = self.make_layer(block, 256, layers[3])\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(6272)\n",
    "        self.max_pool2 = nn.AvgPool2d(8)\n",
    "        self.fc1 = nn.Linear(6272, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                if m.bias is not None:\n",
    "                   # init.constant_(m.bias, 0)\n",
    "                    init.ones_(m.bias)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "            conv3(self.in_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.max_pool1(out)\n",
    "\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.max_pool2(out)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.bn3(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "def custom_resnet(print_net=True):\n",
    "    net_args_resnet = {\n",
    "    \"block\": ResidualBlock,\n",
    "    \"layers\": [3, 4, 6, 4],\n",
    "    \"num_classes\": 5,\n",
    "    \"channels\": 159\n",
    "    }\n",
    "    model = ResNet(**net_args_resnet)\n",
    "    if print_net:\n",
    "        temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f'The model architecture:\\n\\n', model)\n",
    "        print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:30.914754Z",
     "iopub.status.busy": "2020-08-21T11:38:30.914077Z",
     "iopub.status.idle": "2020-08-21T11:38:30.917773Z",
     "shell.execute_reply": "2020-08-21T11:38:30.918243Z"
    },
    "papermill": {
     "duration": 0.018285,
     "end_time": "2020-08-21T11:38:30.918359",
     "exception": false,
     "start_time": "2020-08-21T11:38:30.900074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weighted_nae(inp, targ):\n",
    "    W = torch.FloatTensor([0.3, 0.175, 0.175, 0.175, 0.175]).to(config.device)\n",
    "\n",
    "    return torch.mean(torch.matmul(torch.abs(inp - targ), W/torch.mean(targ, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:30.962028Z",
     "iopub.status.busy": "2020-08-21T11:38:30.960732Z",
     "iopub.status.idle": "2020-08-21T11:38:30.982245Z",
     "shell.execute_reply": "2020-08-21T11:38:30.981699Z"
    },
    "papermill": {
     "duration": 0.037192,
     "end_time": "2020-08-21T11:38:30.982400",
     "exception": false,
     "start_time": "2020-08-21T11:38:30.945208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = int(config.dataset_split*len(train_df))\n",
    "val = train_df[split:].reset_index(drop=True)\n",
    "train = train_df[:split].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_set = TReNDSDataset(test_df, None, config.test_maps_path, False)\n",
    "test_loader = DataLoader(test_set, batch_size=config.val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:31.021297Z",
     "iopub.status.busy": "2020-08-21T11:38:31.020398Z",
     "iopub.status.idle": "2020-08-21T11:38:31.037658Z",
     "shell.execute_reply": "2020-08-21T11:38:31.038195Z"
    },
    "papermill": {
     "duration": 0.046494,
     "end_time": "2020-08-21T11:38:31.038305",
     "exception": false,
     "start_time": "2020-08-21T11:38:30.991811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SCN(53)_vs_SCN(69)</th>\n",
       "      <th>SCN(98)_vs_SCN(69)</th>\n",
       "      <th>SCN(99)_vs_SCN(69)</th>\n",
       "      <th>SCN(45)_vs_SCN(69)</th>\n",
       "      <th>ADN(21)_vs_SCN(69)</th>\n",
       "      <th>ADN(56)_vs_SCN(69)</th>\n",
       "      <th>SMN(3)_vs_SCN(69)</th>\n",
       "      <th>SMN(9)_vs_SCN(69)</th>\n",
       "      <th>SMN(2)_vs_SCN(69)</th>\n",
       "      <th>...</th>\n",
       "      <th>CBN(13)_vs_DMN(94)</th>\n",
       "      <th>CBN(18)_vs_DMN(94)</th>\n",
       "      <th>CBN(4)_vs_DMN(94)</th>\n",
       "      <th>CBN(7)_vs_DMN(94)</th>\n",
       "      <th>CBN(18)_vs_CBN(13)</th>\n",
       "      <th>CBN(4)_vs_CBN(13)</th>\n",
       "      <th>CBN(7)_vs_CBN(13)</th>\n",
       "      <th>CBN(4)_vs_CBN(18)</th>\n",
       "      <th>CBN(7)_vs_CBN(18)</th>\n",
       "      <th>CBN(7)_vs_CBN(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>0.368580</td>\n",
       "      <td>0.166876</td>\n",
       "      <td>0.438148</td>\n",
       "      <td>0.341007</td>\n",
       "      <td>-0.186251</td>\n",
       "      <td>0.049096</td>\n",
       "      <td>0.121417</td>\n",
       "      <td>-0.174268</td>\n",
       "      <td>-0.231578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149279</td>\n",
       "      <td>0.552841</td>\n",
       "      <td>0.131046</td>\n",
       "      <td>0.335446</td>\n",
       "      <td>0.394867</td>\n",
       "      <td>-0.042853</td>\n",
       "      <td>0.124627</td>\n",
       "      <td>-0.060712</td>\n",
       "      <td>0.515964</td>\n",
       "      <td>0.290488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.151696</td>\n",
       "      <td>-0.024819</td>\n",
       "      <td>0.217504</td>\n",
       "      <td>0.418072</td>\n",
       "      <td>-0.227234</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.143832</td>\n",
       "      <td>-0.118116</td>\n",
       "      <td>-0.054825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214216</td>\n",
       "      <td>-0.039792</td>\n",
       "      <td>0.143014</td>\n",
       "      <td>-0.189962</td>\n",
       "      <td>0.498373</td>\n",
       "      <td>0.444231</td>\n",
       "      <td>0.592438</td>\n",
       "      <td>0.028649</td>\n",
       "      <td>0.705524</td>\n",
       "      <td>0.248327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>0.132793</td>\n",
       "      <td>0.258255</td>\n",
       "      <td>0.490769</td>\n",
       "      <td>0.342717</td>\n",
       "      <td>0.091112</td>\n",
       "      <td>0.107969</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>-0.026237</td>\n",
       "      <td>0.094742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130339</td>\n",
       "      <td>0.309540</td>\n",
       "      <td>0.141469</td>\n",
       "      <td>0.030853</td>\n",
       "      <td>0.344394</td>\n",
       "      <td>0.214097</td>\n",
       "      <td>0.317556</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.665937</td>\n",
       "      <td>0.081358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>0.291921</td>\n",
       "      <td>0.251254</td>\n",
       "      <td>0.416470</td>\n",
       "      <td>0.511719</td>\n",
       "      <td>-0.362626</td>\n",
       "      <td>-0.164710</td>\n",
       "      <td>-0.289059</td>\n",
       "      <td>-0.015537</td>\n",
       "      <td>-0.087316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139525</td>\n",
       "      <td>0.394932</td>\n",
       "      <td>0.040443</td>\n",
       "      <td>0.428334</td>\n",
       "      <td>0.498837</td>\n",
       "      <td>0.266755</td>\n",
       "      <td>0.227379</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>0.752343</td>\n",
       "      <td>0.087898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>0.251784</td>\n",
       "      <td>0.571558</td>\n",
       "      <td>0.338475</td>\n",
       "      <td>-0.104604</td>\n",
       "      <td>-0.199365</td>\n",
       "      <td>-0.241106</td>\n",
       "      <td>-0.190934</td>\n",
       "      <td>-0.028470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150218</td>\n",
       "      <td>0.408926</td>\n",
       "      <td>0.072004</td>\n",
       "      <td>0.157582</td>\n",
       "      <td>0.532046</td>\n",
       "      <td>0.355448</td>\n",
       "      <td>0.462675</td>\n",
       "      <td>0.161005</td>\n",
       "      <td>0.703679</td>\n",
       "      <td>0.293607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SCN(53)_vs_SCN(69)  SCN(98)_vs_SCN(69)  SCN(99)_vs_SCN(69)  \\\n",
       "0  10001            0.368580            0.166876            0.438148   \n",
       "1  10002            0.151696           -0.024819            0.217504   \n",
       "2  10004            0.132793            0.258255            0.490769   \n",
       "3  10005            0.291921            0.251254            0.416470   \n",
       "4  10007            0.023588            0.251784            0.571558   \n",
       "\n",
       "   SCN(45)_vs_SCN(69)  ADN(21)_vs_SCN(69)  ADN(56)_vs_SCN(69)  \\\n",
       "0            0.341007           -0.186251            0.049096   \n",
       "1            0.418072           -0.227234           -0.064052   \n",
       "2            0.342717            0.091112            0.107969   \n",
       "3            0.511719           -0.362626           -0.164710   \n",
       "4            0.338475           -0.104604           -0.199365   \n",
       "\n",
       "   SMN(3)_vs_SCN(69)  SMN(9)_vs_SCN(69)  SMN(2)_vs_SCN(69)  ...  \\\n",
       "0           0.121417          -0.174268          -0.231578  ...   \n",
       "1          -0.143832          -0.118116          -0.054825  ...   \n",
       "2           0.029220          -0.026237           0.094742  ...   \n",
       "3          -0.289059          -0.015537          -0.087316  ...   \n",
       "4          -0.241106          -0.190934          -0.028470  ...   \n",
       "\n",
       "   CBN(13)_vs_DMN(94)  CBN(18)_vs_DMN(94)  CBN(4)_vs_DMN(94)  \\\n",
       "0           -0.149279            0.552841           0.131046   \n",
       "1           -0.214216           -0.039792           0.143014   \n",
       "2           -0.130339            0.309540           0.141469   \n",
       "3           -0.139525            0.394932           0.040443   \n",
       "4           -0.150218            0.408926           0.072004   \n",
       "\n",
       "   CBN(7)_vs_DMN(94)  CBN(18)_vs_CBN(13)  CBN(4)_vs_CBN(13)  \\\n",
       "0           0.335446            0.394867          -0.042853   \n",
       "1          -0.189962            0.498373           0.444231   \n",
       "2           0.030853            0.344394           0.214097   \n",
       "3           0.428334            0.498837           0.266755   \n",
       "4           0.157582            0.532046           0.355448   \n",
       "\n",
       "   CBN(7)_vs_CBN(13)  CBN(4)_vs_CBN(18)  CBN(7)_vs_CBN(18)  CBN(7)_vs_CBN(4)  \n",
       "0           0.124627          -0.060712           0.515964          0.290488  \n",
       "1           0.592438           0.028649           0.705524          0.248327  \n",
       "2           0.317556           0.012435           0.665937          0.081358  \n",
       "3           0.227379           0.028984           0.752343          0.087898  \n",
       "4           0.462675           0.161005           0.703679          0.293607  \n",
       "\n",
       "[5 rows x 1379 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:31.066785Z",
     "iopub.status.busy": "2020-08-21T11:38:31.065368Z",
     "iopub.status.idle": "2020-08-21T11:38:31.069374Z",
     "shell.execute_reply": "2020-08-21T11:38:31.068823Z"
    },
    "papermill": {
     "duration": 0.021031,
     "end_time": "2020-08-21T11:38:31.069537",
     "exception": false,
     "start_time": "2020-08-21T11:38:31.048506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logger(elapsed_time, batch_idx, n_batches, epoch, epochs, loss):\n",
    "    tim = 'seconds'\n",
    "    if elapsed_time > 60 and elapsed_time <= 3600:\n",
    "        elapsed_time /= 60\n",
    "        tim = 'minutes'\n",
    "    elif elapsed_time > 3600:\n",
    "        elapsed_time /= 3600\n",
    "        tim = 'hours'\n",
    "    elapsed_time = format(elapsed_time, '.2f')\n",
    "    print(f'Elapsed time: {elapsed_time} {tim}\\tBatch: {batch_idx}/{n_batches}\\tEpoch: {epoch+1}/{epochs}\\tTraining Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:31.108563Z",
     "iopub.status.busy": "2020-08-21T11:38:31.107683Z",
     "iopub.status.idle": "2020-08-21T11:38:31.117270Z",
     "shell.execute_reply": "2020-08-21T11:38:31.116775Z"
    },
    "papermill": {
     "duration": 0.037979,
     "end_time": "2020-08-21T11:38:31.117370",
     "exception": false,
     "start_time": "2020-08-21T11:38:31.079391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model):\n",
    "   \n",
    "    val_set = TReNDSDataset(val, targets, config.train_maps_path, True)\n",
    "    val_loader = DataLoader(val_set, batch_size=config.val_batch_size)\n",
    "    train_set = TReNDSDataset(train, targets, config.train_maps_path, True)\n",
    "    train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True)\n",
    "    \n",
    "    model = model.to(config.device)\n",
    "    lr = config.init_lr\n",
    "    \n",
    "    start_time = time.time()\n",
    "    loss = 0\n",
    "    best=1.0\n",
    "    training_loss, validation_loss = [], []\n",
    "    total, success = 0,0\n",
    "    val_total, val_success = 0,0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        optimizer = Adam(model.parameters(), lr=lr*10**(-epoch), amsgrad=False)\n",
    "        print(f'Learning rate set to {lr*10**(-epoch)}')\n",
    "\n",
    "        for batch_i, train_batch in enumerate(train_loader):\n",
    "            train_img, train_targs = train_batch\n",
    "            train_img = train_img.to(config.device)\n",
    "            train_targs = train_targs.to(config.device)\n",
    "            logger(time.time()-start_time, batch_i, len(train_loader), epoch, config.epochs, loss)\n",
    "           \n",
    "            model.train()\n",
    "            outputs = model.forward(train_img)\n",
    "            \n",
    "            train_targs = train_targs[:,0,:].reshape(train_targs.shape[0], train_targs.shape[2])\n",
    "            loss = weighted_nae(outputs, train_targs)\n",
    "\n",
    "            \n",
    "            training_loss.append(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            del train_img\n",
    "            del train_targs\n",
    "            del outputs\n",
    "            gc.collect()\n",
    "            \n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_targs, val_acc = [], [], []\n",
    "        print('Validating...')\n",
    "        for val_iter, val_batch in enumerate(val_loader):\n",
    "            print(f'Iteration: {val_iter}/{len(val_loader)}')\n",
    "            val_img, val_targ = val_batch\n",
    "            val_targ = val_targ[:,0,:].reshape(val_targ.shape[0], val_targ.shape[2])\n",
    "            val_img, val_targ = val_img.to(config.device), val_targ.to(config.device)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model = model.to(config.device)\n",
    "                val_outputs = model.forward(val_img)\n",
    "                val_preds.append(val_outputs); val_targs.append(val_targ)\n",
    "\n",
    "                del val_outputs\n",
    "                del val_targ\n",
    "                del val_img\n",
    "\n",
    "        val_preds = torch.cat(val_preds, axis=0)\n",
    "        val_targs = torch.cat(val_targs, axis=0)\n",
    "        val_loss = weighted_nae(val_preds, val_targs)\n",
    "        validation_loss.append(val_loss)\n",
    "        if val_loss < best:\n",
    "            best = val_loss\n",
    "            print('Saving model...')\n",
    "            torch.save(model.state_dict(),  config.save_path)\n",
    "            print(f'Model weights saved at \"{config.save_path}\"')\n",
    "\n",
    "        print(f'Validation loss for epoch {epoch+1}: {val_loss:.4f}')\n",
    "\n",
    "        gc.collect()\n",
    "    \n",
    "\n",
    "            \n",
    "    return model, training_loss, validation_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:31.140830Z",
     "iopub.status.busy": "2020-08-21T11:38:31.140159Z",
     "iopub.status.idle": "2020-08-21T11:38:31.223581Z",
     "shell.execute_reply": "2020-08-21T11:38:31.224214Z"
    },
    "papermill": {
     "duration": 0.096735,
     "end_time": "2020-08-21T11:38:31.224396",
     "exception": false,
     "start_time": "2020-08-21T11:38:31.127661",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architecture:\n",
      "\n",
      " ResNet(\n",
      "  (bn): BatchNorm2d(159, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv): Conv2d(159, 32, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (max_pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, padding_mode=replicate)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (drop): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (max_pool2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
      "  (fc1): Linear(in_features=6272, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "The model has 4,507,747 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = custom_resnet(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T11:38:31.256291Z",
     "iopub.status.busy": "2020-08-21T11:38:31.255536Z",
     "iopub.status.idle": "2020-08-21T15:21:54.439416Z",
     "shell.execute_reply": "2020-08-21T15:21:54.438570Z"
    },
    "papermill": {
     "duration": 13403.204072,
     "end_time": "2020-08-21T15:21:54.439555",
     "exception": false,
     "start_time": "2020-08-21T11:38:31.235483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.001\n",
      "Elapsed time: 11.83 seconds\tBatch: 0/147\tEpoch: 1/6\tTraining Loss: 0.0000\n",
      "Elapsed time: 25.02 seconds\tBatch: 1/147\tEpoch: 1/6\tTraining Loss: 1.0002\n",
      "Elapsed time: 37.26 seconds\tBatch: 2/147\tEpoch: 1/6\tTraining Loss: 0.9999\n",
      "Elapsed time: 49.16 seconds\tBatch: 3/147\tEpoch: 1/6\tTraining Loss: 0.9987\n",
      "Elapsed time: 1.01 minutes\tBatch: 4/147\tEpoch: 1/6\tTraining Loss: 0.9964\n",
      "Elapsed time: 1.21 minutes\tBatch: 5/147\tEpoch: 1/6\tTraining Loss: 0.9928\n",
      "Elapsed time: 1.41 minutes\tBatch: 6/147\tEpoch: 1/6\tTraining Loss: 0.9882\n",
      "Elapsed time: 1.61 minutes\tBatch: 7/147\tEpoch: 1/6\tTraining Loss: 0.9803\n",
      "Elapsed time: 1.81 minutes\tBatch: 8/147\tEpoch: 1/6\tTraining Loss: 0.9718\n",
      "Elapsed time: 2.00 minutes\tBatch: 9/147\tEpoch: 1/6\tTraining Loss: 0.9588\n",
      "Elapsed time: 2.19 minutes\tBatch: 10/147\tEpoch: 1/6\tTraining Loss: 0.9458\n",
      "Elapsed time: 2.40 minutes\tBatch: 11/147\tEpoch: 1/6\tTraining Loss: 0.9230\n",
      "Elapsed time: 2.60 minutes\tBatch: 12/147\tEpoch: 1/6\tTraining Loss: 0.8989\n",
      "Elapsed time: 2.79 minutes\tBatch: 13/147\tEpoch: 1/6\tTraining Loss: 0.8702\n",
      "Elapsed time: 2.99 minutes\tBatch: 14/147\tEpoch: 1/6\tTraining Loss: 0.8463\n",
      "Elapsed time: 3.18 minutes\tBatch: 15/147\tEpoch: 1/6\tTraining Loss: 0.8079\n",
      "Elapsed time: 3.36 minutes\tBatch: 16/147\tEpoch: 1/6\tTraining Loss: 0.7659\n",
      "Elapsed time: 3.57 minutes\tBatch: 17/147\tEpoch: 1/6\tTraining Loss: 0.7186\n",
      "Elapsed time: 3.76 minutes\tBatch: 18/147\tEpoch: 1/6\tTraining Loss: 0.6615\n",
      "Elapsed time: 3.96 minutes\tBatch: 19/147\tEpoch: 1/6\tTraining Loss: 0.6406\n",
      "Elapsed time: 4.15 minutes\tBatch: 20/147\tEpoch: 1/6\tTraining Loss: 0.5912\n",
      "Elapsed time: 4.34 minutes\tBatch: 21/147\tEpoch: 1/6\tTraining Loss: 0.5462\n",
      "Elapsed time: 4.54 minutes\tBatch: 22/147\tEpoch: 1/6\tTraining Loss: 0.5206\n",
      "Elapsed time: 4.73 minutes\tBatch: 23/147\tEpoch: 1/6\tTraining Loss: 0.4340\n",
      "Elapsed time: 4.92 minutes\tBatch: 24/147\tEpoch: 1/6\tTraining Loss: 0.4453\n",
      "Elapsed time: 5.12 minutes\tBatch: 25/147\tEpoch: 1/6\tTraining Loss: 0.3984\n",
      "Elapsed time: 5.31 minutes\tBatch: 26/147\tEpoch: 1/6\tTraining Loss: 0.3711\n",
      "Elapsed time: 5.50 minutes\tBatch: 27/147\tEpoch: 1/6\tTraining Loss: 0.4191\n",
      "Elapsed time: 5.70 minutes\tBatch: 28/147\tEpoch: 1/6\tTraining Loss: 0.3252\n",
      "Elapsed time: 5.88 minutes\tBatch: 29/147\tEpoch: 1/6\tTraining Loss: 0.4520\n",
      "Elapsed time: 6.08 minutes\tBatch: 30/147\tEpoch: 1/6\tTraining Loss: 0.3971\n",
      "Elapsed time: 6.26 minutes\tBatch: 31/147\tEpoch: 1/6\tTraining Loss: 0.3753\n",
      "Elapsed time: 6.46 minutes\tBatch: 32/147\tEpoch: 1/6\tTraining Loss: 0.4139\n",
      "Elapsed time: 6.65 minutes\tBatch: 33/147\tEpoch: 1/6\tTraining Loss: 0.4807\n",
      "Elapsed time: 6.84 minutes\tBatch: 34/147\tEpoch: 1/6\tTraining Loss: 0.3643\n",
      "Elapsed time: 7.04 minutes\tBatch: 35/147\tEpoch: 1/6\tTraining Loss: 0.3678\n",
      "Elapsed time: 7.23 minutes\tBatch: 36/147\tEpoch: 1/6\tTraining Loss: 0.3477\n",
      "Elapsed time: 7.42 minutes\tBatch: 37/147\tEpoch: 1/6\tTraining Loss: 0.3737\n",
      "Elapsed time: 7.62 minutes\tBatch: 38/147\tEpoch: 1/6\tTraining Loss: 0.3993\n",
      "Elapsed time: 7.81 minutes\tBatch: 39/147\tEpoch: 1/6\tTraining Loss: 0.4170\n",
      "Elapsed time: 8.00 minutes\tBatch: 40/147\tEpoch: 1/6\tTraining Loss: 0.3520\n",
      "Elapsed time: 8.19 minutes\tBatch: 41/147\tEpoch: 1/6\tTraining Loss: 0.3463\n",
      "Elapsed time: 8.38 minutes\tBatch: 42/147\tEpoch: 1/6\tTraining Loss: 0.3407\n",
      "Elapsed time: 8.57 minutes\tBatch: 43/147\tEpoch: 1/6\tTraining Loss: 0.3196\n",
      "Elapsed time: 8.76 minutes\tBatch: 44/147\tEpoch: 1/6\tTraining Loss: 0.3642\n",
      "Elapsed time: 8.95 minutes\tBatch: 45/147\tEpoch: 1/6\tTraining Loss: 0.3757\n",
      "Elapsed time: 9.15 minutes\tBatch: 46/147\tEpoch: 1/6\tTraining Loss: 0.3506\n",
      "Elapsed time: 9.33 minutes\tBatch: 47/147\tEpoch: 1/6\tTraining Loss: 0.3086\n",
      "Elapsed time: 9.53 minutes\tBatch: 48/147\tEpoch: 1/6\tTraining Loss: 0.3379\n",
      "Elapsed time: 9.73 minutes\tBatch: 49/147\tEpoch: 1/6\tTraining Loss: 0.3437\n",
      "Elapsed time: 9.92 minutes\tBatch: 50/147\tEpoch: 1/6\tTraining Loss: 0.3026\n",
      "Elapsed time: 10.12 minutes\tBatch: 51/147\tEpoch: 1/6\tTraining Loss: 0.3377\n",
      "Elapsed time: 10.31 minutes\tBatch: 52/147\tEpoch: 1/6\tTraining Loss: 0.3103\n",
      "Elapsed time: 10.51 minutes\tBatch: 53/147\tEpoch: 1/6\tTraining Loss: 0.3037\n",
      "Elapsed time: 10.71 minutes\tBatch: 54/147\tEpoch: 1/6\tTraining Loss: 0.2811\n",
      "Elapsed time: 10.90 minutes\tBatch: 55/147\tEpoch: 1/6\tTraining Loss: 0.2844\n",
      "Elapsed time: 11.09 minutes\tBatch: 56/147\tEpoch: 1/6\tTraining Loss: 0.2776\n",
      "Elapsed time: 11.28 minutes\tBatch: 57/147\tEpoch: 1/6\tTraining Loss: 0.3673\n",
      "Elapsed time: 11.48 minutes\tBatch: 58/147\tEpoch: 1/6\tTraining Loss: 0.3289\n",
      "Elapsed time: 11.67 minutes\tBatch: 59/147\tEpoch: 1/6\tTraining Loss: 0.2391\n",
      "Elapsed time: 11.86 minutes\tBatch: 60/147\tEpoch: 1/6\tTraining Loss: 0.2415\n",
      "Elapsed time: 12.05 minutes\tBatch: 61/147\tEpoch: 1/6\tTraining Loss: 0.2882\n",
      "Elapsed time: 12.24 minutes\tBatch: 62/147\tEpoch: 1/6\tTraining Loss: 0.2802\n",
      "Elapsed time: 12.44 minutes\tBatch: 63/147\tEpoch: 1/6\tTraining Loss: 0.3179\n",
      "Elapsed time: 12.63 minutes\tBatch: 64/147\tEpoch: 1/6\tTraining Loss: 0.3590\n",
      "Elapsed time: 12.82 minutes\tBatch: 65/147\tEpoch: 1/6\tTraining Loss: 0.2628\n",
      "Elapsed time: 13.01 minutes\tBatch: 66/147\tEpoch: 1/6\tTraining Loss: 0.3321\n",
      "Elapsed time: 13.21 minutes\tBatch: 67/147\tEpoch: 1/6\tTraining Loss: 0.3121\n",
      "Elapsed time: 13.40 minutes\tBatch: 68/147\tEpoch: 1/6\tTraining Loss: 0.3232\n",
      "Elapsed time: 13.60 minutes\tBatch: 69/147\tEpoch: 1/6\tTraining Loss: 0.2515\n",
      "Elapsed time: 13.79 minutes\tBatch: 70/147\tEpoch: 1/6\tTraining Loss: 0.2899\n",
      "Elapsed time: 13.99 minutes\tBatch: 71/147\tEpoch: 1/6\tTraining Loss: 0.3495\n",
      "Elapsed time: 14.18 minutes\tBatch: 72/147\tEpoch: 1/6\tTraining Loss: 0.3614\n",
      "Elapsed time: 14.37 minutes\tBatch: 73/147\tEpoch: 1/6\tTraining Loss: 0.2452\n",
      "Elapsed time: 14.57 minutes\tBatch: 74/147\tEpoch: 1/6\tTraining Loss: 0.2846\n",
      "Elapsed time: 14.76 minutes\tBatch: 75/147\tEpoch: 1/6\tTraining Loss: 0.2649\n",
      "Elapsed time: 14.95 minutes\tBatch: 76/147\tEpoch: 1/6\tTraining Loss: 0.3040\n",
      "Elapsed time: 15.14 minutes\tBatch: 77/147\tEpoch: 1/6\tTraining Loss: 0.3067\n",
      "Elapsed time: 15.33 minutes\tBatch: 78/147\tEpoch: 1/6\tTraining Loss: 0.2946\n",
      "Elapsed time: 15.54 minutes\tBatch: 79/147\tEpoch: 1/6\tTraining Loss: 0.2350\n",
      "Elapsed time: 15.73 minutes\tBatch: 80/147\tEpoch: 1/6\tTraining Loss: 0.2478\n",
      "Elapsed time: 15.92 minutes\tBatch: 81/147\tEpoch: 1/6\tTraining Loss: 0.2902\n",
      "Elapsed time: 16.11 minutes\tBatch: 82/147\tEpoch: 1/6\tTraining Loss: 0.2746\n",
      "Elapsed time: 16.30 minutes\tBatch: 83/147\tEpoch: 1/6\tTraining Loss: 0.2753\n",
      "Elapsed time: 16.51 minutes\tBatch: 84/147\tEpoch: 1/6\tTraining Loss: 0.3225\n",
      "Elapsed time: 16.70 minutes\tBatch: 85/147\tEpoch: 1/6\tTraining Loss: 0.2621\n",
      "Elapsed time: 16.90 minutes\tBatch: 86/147\tEpoch: 1/6\tTraining Loss: 0.2366\n",
      "Elapsed time: 17.09 minutes\tBatch: 87/147\tEpoch: 1/6\tTraining Loss: 0.2635\n",
      "Elapsed time: 17.28 minutes\tBatch: 88/147\tEpoch: 1/6\tTraining Loss: 0.2566\n",
      "Elapsed time: 17.48 minutes\tBatch: 89/147\tEpoch: 1/6\tTraining Loss: 0.3195\n",
      "Elapsed time: 17.68 minutes\tBatch: 90/147\tEpoch: 1/6\tTraining Loss: 0.2761\n",
      "Elapsed time: 17.87 minutes\tBatch: 91/147\tEpoch: 1/6\tTraining Loss: 0.2772\n",
      "Elapsed time: 18.07 minutes\tBatch: 92/147\tEpoch: 1/6\tTraining Loss: 0.2705\n",
      "Elapsed time: 18.26 minutes\tBatch: 93/147\tEpoch: 1/6\tTraining Loss: 0.2708\n",
      "Elapsed time: 18.45 minutes\tBatch: 94/147\tEpoch: 1/6\tTraining Loss: 0.2959\n",
      "Elapsed time: 18.65 minutes\tBatch: 95/147\tEpoch: 1/6\tTraining Loss: 0.2397\n",
      "Elapsed time: 18.84 minutes\tBatch: 96/147\tEpoch: 1/6\tTraining Loss: 0.2430\n",
      "Elapsed time: 19.03 minutes\tBatch: 97/147\tEpoch: 1/6\tTraining Loss: 0.2261\n",
      "Elapsed time: 19.23 minutes\tBatch: 98/147\tEpoch: 1/6\tTraining Loss: 0.3135\n",
      "Elapsed time: 19.43 minutes\tBatch: 99/147\tEpoch: 1/6\tTraining Loss: 0.2360\n",
      "Elapsed time: 19.63 minutes\tBatch: 100/147\tEpoch: 1/6\tTraining Loss: 0.2790\n",
      "Elapsed time: 19.82 minutes\tBatch: 101/147\tEpoch: 1/6\tTraining Loss: 0.2797\n",
      "Elapsed time: 20.01 minutes\tBatch: 102/147\tEpoch: 1/6\tTraining Loss: 0.2888\n",
      "Elapsed time: 20.20 minutes\tBatch: 103/147\tEpoch: 1/6\tTraining Loss: 0.2621\n",
      "Elapsed time: 20.39 minutes\tBatch: 104/147\tEpoch: 1/6\tTraining Loss: 0.2526\n",
      "Elapsed time: 20.60 minutes\tBatch: 105/147\tEpoch: 1/6\tTraining Loss: 0.2518\n",
      "Elapsed time: 20.79 minutes\tBatch: 106/147\tEpoch: 1/6\tTraining Loss: 0.3035\n",
      "Elapsed time: 20.99 minutes\tBatch: 107/147\tEpoch: 1/6\tTraining Loss: 0.2724\n",
      "Elapsed time: 21.18 minutes\tBatch: 108/147\tEpoch: 1/6\tTraining Loss: 0.2212\n",
      "Elapsed time: 21.37 minutes\tBatch: 109/147\tEpoch: 1/6\tTraining Loss: 0.2800\n",
      "Elapsed time: 21.57 minutes\tBatch: 110/147\tEpoch: 1/6\tTraining Loss: 0.2491\n",
      "Elapsed time: 21.77 minutes\tBatch: 111/147\tEpoch: 1/6\tTraining Loss: 0.2481\n",
      "Elapsed time: 21.95 minutes\tBatch: 112/147\tEpoch: 1/6\tTraining Loss: 0.2287\n",
      "Elapsed time: 22.15 minutes\tBatch: 113/147\tEpoch: 1/6\tTraining Loss: 0.2371\n",
      "Elapsed time: 22.35 minutes\tBatch: 114/147\tEpoch: 1/6\tTraining Loss: 0.2845\n",
      "Elapsed time: 22.55 minutes\tBatch: 115/147\tEpoch: 1/6\tTraining Loss: 0.2221\n",
      "Elapsed time: 22.76 minutes\tBatch: 116/147\tEpoch: 1/6\tTraining Loss: 0.2340\n",
      "Elapsed time: 22.95 minutes\tBatch: 117/147\tEpoch: 1/6\tTraining Loss: 0.2610\n",
      "Elapsed time: 23.15 minutes\tBatch: 118/147\tEpoch: 1/6\tTraining Loss: 0.2498\n",
      "Elapsed time: 23.35 minutes\tBatch: 119/147\tEpoch: 1/6\tTraining Loss: 0.2233\n",
      "Elapsed time: 23.55 minutes\tBatch: 120/147\tEpoch: 1/6\tTraining Loss: 0.2378\n",
      "Elapsed time: 23.75 minutes\tBatch: 121/147\tEpoch: 1/6\tTraining Loss: 0.2472\n",
      "Elapsed time: 23.94 minutes\tBatch: 122/147\tEpoch: 1/6\tTraining Loss: 0.2382\n",
      "Elapsed time: 24.13 minutes\tBatch: 123/147\tEpoch: 1/6\tTraining Loss: 0.2284\n",
      "Elapsed time: 24.33 minutes\tBatch: 124/147\tEpoch: 1/6\tTraining Loss: 0.2558\n",
      "Elapsed time: 24.53 minutes\tBatch: 125/147\tEpoch: 1/6\tTraining Loss: 0.2240\n",
      "Elapsed time: 24.74 minutes\tBatch: 126/147\tEpoch: 1/6\tTraining Loss: 0.2383\n",
      "Elapsed time: 24.94 minutes\tBatch: 127/147\tEpoch: 1/6\tTraining Loss: 0.2658\n",
      "Elapsed time: 25.14 minutes\tBatch: 128/147\tEpoch: 1/6\tTraining Loss: 0.2086\n",
      "Elapsed time: 25.34 minutes\tBatch: 129/147\tEpoch: 1/6\tTraining Loss: 0.2446\n",
      "Elapsed time: 25.55 minutes\tBatch: 130/147\tEpoch: 1/6\tTraining Loss: 0.2053\n",
      "Elapsed time: 25.76 minutes\tBatch: 131/147\tEpoch: 1/6\tTraining Loss: 0.2221\n",
      "Elapsed time: 26.21 minutes\tBatch: 132/147\tEpoch: 1/6\tTraining Loss: 0.2587\n",
      "Elapsed time: 26.42 minutes\tBatch: 133/147\tEpoch: 1/6\tTraining Loss: 0.2240\n",
      "Elapsed time: 26.64 minutes\tBatch: 134/147\tEpoch: 1/6\tTraining Loss: 0.2172\n",
      "Elapsed time: 26.87 minutes\tBatch: 135/147\tEpoch: 1/6\tTraining Loss: 0.2440\n",
      "Elapsed time: 27.09 minutes\tBatch: 136/147\tEpoch: 1/6\tTraining Loss: 0.2481\n",
      "Elapsed time: 27.30 minutes\tBatch: 137/147\tEpoch: 1/6\tTraining Loss: 0.2410\n",
      "Elapsed time: 27.54 minutes\tBatch: 138/147\tEpoch: 1/6\tTraining Loss: 0.2461\n",
      "Elapsed time: 27.76 minutes\tBatch: 139/147\tEpoch: 1/6\tTraining Loss: 0.2513\n",
      "Elapsed time: 27.97 minutes\tBatch: 140/147\tEpoch: 1/6\tTraining Loss: 0.2470\n",
      "Elapsed time: 28.17 minutes\tBatch: 141/147\tEpoch: 1/6\tTraining Loss: 0.2273\n",
      "Elapsed time: 28.37 minutes\tBatch: 142/147\tEpoch: 1/6\tTraining Loss: 0.2530\n",
      "Elapsed time: 28.59 minutes\tBatch: 143/147\tEpoch: 1/6\tTraining Loss: 0.2225\n",
      "Elapsed time: 28.79 minutes\tBatch: 144/147\tEpoch: 1/6\tTraining Loss: 0.2132\n",
      "Elapsed time: 29.00 minutes\tBatch: 145/147\tEpoch: 1/6\tTraining Loss: 0.2448\n",
      "Elapsed time: 29.19 minutes\tBatch: 146/147\tEpoch: 1/6\tTraining Loss: 0.2351\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Saving model...\n",
      "Model weights saved at \"rn_model.pt\"\n",
      "Validation loss for epoch 1: 0.1945\n",
      "Learning rate set to 0.0001\n",
      "Elapsed time: 36.49 minutes\tBatch: 0/147\tEpoch: 2/6\tTraining Loss: 0.2309\n",
      "Elapsed time: 36.68 minutes\tBatch: 1/147\tEpoch: 2/6\tTraining Loss: 0.2414\n",
      "Elapsed time: 36.87 minutes\tBatch: 2/147\tEpoch: 2/6\tTraining Loss: 0.2384\n",
      "Elapsed time: 37.06 minutes\tBatch: 3/147\tEpoch: 2/6\tTraining Loss: 0.3094\n",
      "Elapsed time: 37.26 minutes\tBatch: 4/147\tEpoch: 2/6\tTraining Loss: 0.2540\n",
      "Elapsed time: 37.45 minutes\tBatch: 5/147\tEpoch: 2/6\tTraining Loss: 0.2227\n",
      "Elapsed time: 37.65 minutes\tBatch: 6/147\tEpoch: 2/6\tTraining Loss: 0.2162\n",
      "Elapsed time: 37.84 minutes\tBatch: 7/147\tEpoch: 2/6\tTraining Loss: 0.2652\n",
      "Elapsed time: 38.03 minutes\tBatch: 8/147\tEpoch: 2/6\tTraining Loss: 0.2245\n",
      "Elapsed time: 38.22 minutes\tBatch: 9/147\tEpoch: 2/6\tTraining Loss: 0.2058\n",
      "Elapsed time: 38.42 minutes\tBatch: 10/147\tEpoch: 2/6\tTraining Loss: 0.2880\n",
      "Elapsed time: 38.62 minutes\tBatch: 11/147\tEpoch: 2/6\tTraining Loss: 0.2292\n",
      "Elapsed time: 38.81 minutes\tBatch: 12/147\tEpoch: 2/6\tTraining Loss: 0.2209\n",
      "Elapsed time: 39.00 minutes\tBatch: 13/147\tEpoch: 2/6\tTraining Loss: 0.2281\n",
      "Elapsed time: 39.19 minutes\tBatch: 14/147\tEpoch: 2/6\tTraining Loss: 0.2320\n",
      "Elapsed time: 39.39 minutes\tBatch: 15/147\tEpoch: 2/6\tTraining Loss: 0.2353\n",
      "Elapsed time: 39.59 minutes\tBatch: 16/147\tEpoch: 2/6\tTraining Loss: 0.2402\n",
      "Elapsed time: 39.78 minutes\tBatch: 17/147\tEpoch: 2/6\tTraining Loss: 0.2203\n",
      "Elapsed time: 39.98 minutes\tBatch: 18/147\tEpoch: 2/6\tTraining Loss: 0.2472\n",
      "Elapsed time: 40.18 minutes\tBatch: 19/147\tEpoch: 2/6\tTraining Loss: 0.2238\n",
      "Elapsed time: 40.37 minutes\tBatch: 20/147\tEpoch: 2/6\tTraining Loss: 0.2794\n",
      "Elapsed time: 40.58 minutes\tBatch: 21/147\tEpoch: 2/6\tTraining Loss: 0.2536\n",
      "Elapsed time: 40.77 minutes\tBatch: 22/147\tEpoch: 2/6\tTraining Loss: 0.2229\n",
      "Elapsed time: 40.96 minutes\tBatch: 23/147\tEpoch: 2/6\tTraining Loss: 0.2272\n",
      "Elapsed time: 41.16 minutes\tBatch: 24/147\tEpoch: 2/6\tTraining Loss: 0.2045\n",
      "Elapsed time: 41.35 minutes\tBatch: 25/147\tEpoch: 2/6\tTraining Loss: 0.2517\n",
      "Elapsed time: 41.56 minutes\tBatch: 26/147\tEpoch: 2/6\tTraining Loss: 0.2338\n",
      "Elapsed time: 41.76 minutes\tBatch: 27/147\tEpoch: 2/6\tTraining Loss: 0.2492\n",
      "Elapsed time: 41.97 minutes\tBatch: 28/147\tEpoch: 2/6\tTraining Loss: 0.2476\n",
      "Elapsed time: 42.17 minutes\tBatch: 29/147\tEpoch: 2/6\tTraining Loss: 0.2011\n",
      "Elapsed time: 42.39 minutes\tBatch: 30/147\tEpoch: 2/6\tTraining Loss: 0.2289\n",
      "Elapsed time: 42.61 minutes\tBatch: 31/147\tEpoch: 2/6\tTraining Loss: 0.2102\n",
      "Elapsed time: 42.81 minutes\tBatch: 32/147\tEpoch: 2/6\tTraining Loss: 0.2678\n",
      "Elapsed time: 43.01 minutes\tBatch: 33/147\tEpoch: 2/6\tTraining Loss: 0.2662\n",
      "Elapsed time: 43.21 minutes\tBatch: 34/147\tEpoch: 2/6\tTraining Loss: 0.2272\n",
      "Elapsed time: 43.40 minutes\tBatch: 35/147\tEpoch: 2/6\tTraining Loss: 0.2246\n",
      "Elapsed time: 43.62 minutes\tBatch: 36/147\tEpoch: 2/6\tTraining Loss: 0.2131\n",
      "Elapsed time: 43.81 minutes\tBatch: 37/147\tEpoch: 2/6\tTraining Loss: 0.2629\n",
      "Elapsed time: 44.02 minutes\tBatch: 38/147\tEpoch: 2/6\tTraining Loss: 0.2068\n",
      "Elapsed time: 44.22 minutes\tBatch: 39/147\tEpoch: 2/6\tTraining Loss: 0.2531\n",
      "Elapsed time: 44.42 minutes\tBatch: 40/147\tEpoch: 2/6\tTraining Loss: 0.2317\n",
      "Elapsed time: 44.63 minutes\tBatch: 41/147\tEpoch: 2/6\tTraining Loss: 0.2241\n",
      "Elapsed time: 44.82 minutes\tBatch: 42/147\tEpoch: 2/6\tTraining Loss: 0.2332\n",
      "Elapsed time: 45.02 minutes\tBatch: 43/147\tEpoch: 2/6\tTraining Loss: 0.2612\n",
      "Elapsed time: 45.22 minutes\tBatch: 44/147\tEpoch: 2/6\tTraining Loss: 0.2470\n",
      "Elapsed time: 45.43 minutes\tBatch: 45/147\tEpoch: 2/6\tTraining Loss: 0.2976\n",
      "Elapsed time: 45.64 minutes\tBatch: 46/147\tEpoch: 2/6\tTraining Loss: 0.2157\n",
      "Elapsed time: 45.84 minutes\tBatch: 47/147\tEpoch: 2/6\tTraining Loss: 0.2081\n",
      "Elapsed time: 46.04 minutes\tBatch: 48/147\tEpoch: 2/6\tTraining Loss: 0.2205\n",
      "Elapsed time: 46.24 minutes\tBatch: 49/147\tEpoch: 2/6\tTraining Loss: 0.2419\n",
      "Elapsed time: 46.44 minutes\tBatch: 50/147\tEpoch: 2/6\tTraining Loss: 0.2841\n",
      "Elapsed time: 46.65 minutes\tBatch: 51/147\tEpoch: 2/6\tTraining Loss: 0.1928\n",
      "Elapsed time: 46.85 minutes\tBatch: 52/147\tEpoch: 2/6\tTraining Loss: 0.2403\n",
      "Elapsed time: 47.05 minutes\tBatch: 53/147\tEpoch: 2/6\tTraining Loss: 0.2565\n",
      "Elapsed time: 47.25 minutes\tBatch: 54/147\tEpoch: 2/6\tTraining Loss: 0.2009\n",
      "Elapsed time: 47.46 minutes\tBatch: 55/147\tEpoch: 2/6\tTraining Loss: 0.2183\n",
      "Elapsed time: 47.66 minutes\tBatch: 56/147\tEpoch: 2/6\tTraining Loss: 0.2673\n",
      "Elapsed time: 47.87 minutes\tBatch: 57/147\tEpoch: 2/6\tTraining Loss: 0.2315\n",
      "Elapsed time: 48.07 minutes\tBatch: 58/147\tEpoch: 2/6\tTraining Loss: 0.2157\n",
      "Elapsed time: 48.27 minutes\tBatch: 59/147\tEpoch: 2/6\tTraining Loss: 0.2148\n",
      "Elapsed time: 48.48 minutes\tBatch: 60/147\tEpoch: 2/6\tTraining Loss: 0.1829\n",
      "Elapsed time: 48.70 minutes\tBatch: 61/147\tEpoch: 2/6\tTraining Loss: 0.2480\n",
      "Elapsed time: 48.91 minutes\tBatch: 62/147\tEpoch: 2/6\tTraining Loss: 0.2320\n",
      "Elapsed time: 49.13 minutes\tBatch: 63/147\tEpoch: 2/6\tTraining Loss: 0.2447\n",
      "Elapsed time: 49.35 minutes\tBatch: 64/147\tEpoch: 2/6\tTraining Loss: 0.2173\n",
      "Elapsed time: 49.56 minutes\tBatch: 65/147\tEpoch: 2/6\tTraining Loss: 0.2604\n",
      "Elapsed time: 49.76 minutes\tBatch: 66/147\tEpoch: 2/6\tTraining Loss: 0.2410\n",
      "Elapsed time: 49.97 minutes\tBatch: 67/147\tEpoch: 2/6\tTraining Loss: 0.2395\n",
      "Elapsed time: 50.17 minutes\tBatch: 68/147\tEpoch: 2/6\tTraining Loss: 0.1983\n",
      "Elapsed time: 50.38 minutes\tBatch: 69/147\tEpoch: 2/6\tTraining Loss: 0.1983\n",
      "Elapsed time: 50.60 minutes\tBatch: 70/147\tEpoch: 2/6\tTraining Loss: 0.2242\n",
      "Elapsed time: 50.81 minutes\tBatch: 71/147\tEpoch: 2/6\tTraining Loss: 0.2535\n",
      "Elapsed time: 51.02 minutes\tBatch: 72/147\tEpoch: 2/6\tTraining Loss: 0.2317\n",
      "Elapsed time: 51.21 minutes\tBatch: 73/147\tEpoch: 2/6\tTraining Loss: 0.2475\n",
      "Elapsed time: 51.42 minutes\tBatch: 74/147\tEpoch: 2/6\tTraining Loss: 0.2253\n",
      "Elapsed time: 51.63 minutes\tBatch: 75/147\tEpoch: 2/6\tTraining Loss: 0.2140\n",
      "Elapsed time: 51.82 minutes\tBatch: 76/147\tEpoch: 2/6\tTraining Loss: 0.2420\n",
      "Elapsed time: 52.02 minutes\tBatch: 77/147\tEpoch: 2/6\tTraining Loss: 0.2210\n",
      "Elapsed time: 52.22 minutes\tBatch: 78/147\tEpoch: 2/6\tTraining Loss: 0.2089\n",
      "Elapsed time: 52.41 minutes\tBatch: 79/147\tEpoch: 2/6\tTraining Loss: 0.2438\n",
      "Elapsed time: 52.61 minutes\tBatch: 80/147\tEpoch: 2/6\tTraining Loss: 0.1951\n",
      "Elapsed time: 52.81 minutes\tBatch: 81/147\tEpoch: 2/6\tTraining Loss: 0.2610\n",
      "Elapsed time: 53.01 minutes\tBatch: 82/147\tEpoch: 2/6\tTraining Loss: 0.2047\n",
      "Elapsed time: 53.20 minutes\tBatch: 83/147\tEpoch: 2/6\tTraining Loss: 0.2032\n",
      "Elapsed time: 53.39 minutes\tBatch: 84/147\tEpoch: 2/6\tTraining Loss: 0.2531\n",
      "Elapsed time: 53.60 minutes\tBatch: 85/147\tEpoch: 2/6\tTraining Loss: 0.2466\n",
      "Elapsed time: 53.79 minutes\tBatch: 86/147\tEpoch: 2/6\tTraining Loss: 0.2061\n",
      "Elapsed time: 53.99 minutes\tBatch: 87/147\tEpoch: 2/6\tTraining Loss: 0.2218\n",
      "Elapsed time: 54.19 minutes\tBatch: 88/147\tEpoch: 2/6\tTraining Loss: 0.2035\n",
      "Elapsed time: 54.38 minutes\tBatch: 89/147\tEpoch: 2/6\tTraining Loss: 0.2246\n",
      "Elapsed time: 54.59 minutes\tBatch: 90/147\tEpoch: 2/6\tTraining Loss: 0.2516\n",
      "Elapsed time: 54.79 minutes\tBatch: 91/147\tEpoch: 2/6\tTraining Loss: 0.1840\n",
      "Elapsed time: 54.98 minutes\tBatch: 92/147\tEpoch: 2/6\tTraining Loss: 0.2381\n",
      "Elapsed time: 55.18 minutes\tBatch: 93/147\tEpoch: 2/6\tTraining Loss: 0.2319\n",
      "Elapsed time: 55.38 minutes\tBatch: 94/147\tEpoch: 2/6\tTraining Loss: 0.2217\n",
      "Elapsed time: 55.60 minutes\tBatch: 95/147\tEpoch: 2/6\tTraining Loss: 0.2280\n",
      "Elapsed time: 55.80 minutes\tBatch: 96/147\tEpoch: 2/6\tTraining Loss: 0.2612\n",
      "Elapsed time: 56.00 minutes\tBatch: 97/147\tEpoch: 2/6\tTraining Loss: 0.2441\n",
      "Elapsed time: 56.21 minutes\tBatch: 98/147\tEpoch: 2/6\tTraining Loss: 0.2400\n",
      "Elapsed time: 56.42 minutes\tBatch: 99/147\tEpoch: 2/6\tTraining Loss: 0.2359\n",
      "Elapsed time: 56.63 minutes\tBatch: 100/147\tEpoch: 2/6\tTraining Loss: 0.2164\n",
      "Elapsed time: 56.85 minutes\tBatch: 101/147\tEpoch: 2/6\tTraining Loss: 0.2123\n",
      "Elapsed time: 57.06 minutes\tBatch: 102/147\tEpoch: 2/6\tTraining Loss: 0.2297\n",
      "Elapsed time: 57.27 minutes\tBatch: 103/147\tEpoch: 2/6\tTraining Loss: 0.2174\n",
      "Elapsed time: 57.47 minutes\tBatch: 104/147\tEpoch: 2/6\tTraining Loss: 0.2291\n",
      "Elapsed time: 57.67 minutes\tBatch: 105/147\tEpoch: 2/6\tTraining Loss: 0.2375\n",
      "Elapsed time: 57.86 minutes\tBatch: 106/147\tEpoch: 2/6\tTraining Loss: 0.2685\n",
      "Elapsed time: 58.06 minutes\tBatch: 107/147\tEpoch: 2/6\tTraining Loss: 0.2376\n",
      "Elapsed time: 58.26 minutes\tBatch: 108/147\tEpoch: 2/6\tTraining Loss: 0.1941\n",
      "Elapsed time: 58.46 minutes\tBatch: 109/147\tEpoch: 2/6\tTraining Loss: 0.1962\n",
      "Elapsed time: 58.65 minutes\tBatch: 110/147\tEpoch: 2/6\tTraining Loss: 0.2500\n",
      "Elapsed time: 58.86 minutes\tBatch: 111/147\tEpoch: 2/6\tTraining Loss: 0.1992\n",
      "Elapsed time: 59.05 minutes\tBatch: 112/147\tEpoch: 2/6\tTraining Loss: 0.2054\n",
      "Elapsed time: 59.24 minutes\tBatch: 113/147\tEpoch: 2/6\tTraining Loss: 0.2257\n",
      "Elapsed time: 59.45 minutes\tBatch: 114/147\tEpoch: 2/6\tTraining Loss: 0.2133\n",
      "Elapsed time: 59.65 minutes\tBatch: 115/147\tEpoch: 2/6\tTraining Loss: 0.2663\n",
      "Elapsed time: 59.85 minutes\tBatch: 116/147\tEpoch: 2/6\tTraining Loss: 0.2044\n",
      "Elapsed time: 1.00 hours\tBatch: 117/147\tEpoch: 2/6\tTraining Loss: 0.2503\n",
      "Elapsed time: 1.00 hours\tBatch: 118/147\tEpoch: 2/6\tTraining Loss: 0.2305\n",
      "Elapsed time: 1.01 hours\tBatch: 119/147\tEpoch: 2/6\tTraining Loss: 0.2088\n",
      "Elapsed time: 1.01 hours\tBatch: 120/147\tEpoch: 2/6\tTraining Loss: 0.1986\n",
      "Elapsed time: 1.01 hours\tBatch: 121/147\tEpoch: 2/6\tTraining Loss: 0.2167\n",
      "Elapsed time: 1.02 hours\tBatch: 122/147\tEpoch: 2/6\tTraining Loss: 0.2255\n",
      "Elapsed time: 1.02 hours\tBatch: 123/147\tEpoch: 2/6\tTraining Loss: 0.2239\n",
      "Elapsed time: 1.03 hours\tBatch: 124/147\tEpoch: 2/6\tTraining Loss: 0.2372\n",
      "Elapsed time: 1.03 hours\tBatch: 125/147\tEpoch: 2/6\tTraining Loss: 0.2484\n",
      "Elapsed time: 1.03 hours\tBatch: 126/147\tEpoch: 2/6\tTraining Loss: 0.2005\n",
      "Elapsed time: 1.04 hours\tBatch: 127/147\tEpoch: 2/6\tTraining Loss: 0.2533\n",
      "Elapsed time: 1.04 hours\tBatch: 128/147\tEpoch: 2/6\tTraining Loss: 0.2049\n",
      "Elapsed time: 1.04 hours\tBatch: 129/147\tEpoch: 2/6\tTraining Loss: 0.2239\n",
      "Elapsed time: 1.05 hours\tBatch: 130/147\tEpoch: 2/6\tTraining Loss: 0.2686\n",
      "Elapsed time: 1.05 hours\tBatch: 131/147\tEpoch: 2/6\tTraining Loss: 0.2382\n",
      "Elapsed time: 1.05 hours\tBatch: 132/147\tEpoch: 2/6\tTraining Loss: 0.2018\n",
      "Elapsed time: 1.06 hours\tBatch: 133/147\tEpoch: 2/6\tTraining Loss: 0.2429\n",
      "Elapsed time: 1.06 hours\tBatch: 134/147\tEpoch: 2/6\tTraining Loss: 0.2343\n",
      "Elapsed time: 1.06 hours\tBatch: 135/147\tEpoch: 2/6\tTraining Loss: 0.2479\n",
      "Elapsed time: 1.07 hours\tBatch: 136/147\tEpoch: 2/6\tTraining Loss: 0.2144\n",
      "Elapsed time: 1.07 hours\tBatch: 137/147\tEpoch: 2/6\tTraining Loss: 0.2501\n",
      "Elapsed time: 1.07 hours\tBatch: 138/147\tEpoch: 2/6\tTraining Loss: 0.1963\n",
      "Elapsed time: 1.08 hours\tBatch: 139/147\tEpoch: 2/6\tTraining Loss: 0.2370\n",
      "Elapsed time: 1.08 hours\tBatch: 140/147\tEpoch: 2/6\tTraining Loss: 0.2596\n",
      "Elapsed time: 1.08 hours\tBatch: 141/147\tEpoch: 2/6\tTraining Loss: 0.2231\n",
      "Elapsed time: 1.09 hours\tBatch: 142/147\tEpoch: 2/6\tTraining Loss: 0.2237\n",
      "Elapsed time: 1.09 hours\tBatch: 143/147\tEpoch: 2/6\tTraining Loss: 0.1912\n",
      "Elapsed time: 1.09 hours\tBatch: 144/147\tEpoch: 2/6\tTraining Loss: 0.2281\n",
      "Elapsed time: 1.10 hours\tBatch: 145/147\tEpoch: 2/6\tTraining Loss: 0.2402\n",
      "Elapsed time: 1.10 hours\tBatch: 146/147\tEpoch: 2/6\tTraining Loss: 0.2099\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Saving model...\n",
      "Model weights saved at \"rn_model.pt\"\n",
      "Validation loss for epoch 2: 0.1868\n",
      "Learning rate set to 1e-05\n",
      "Elapsed time: 1.22 hours\tBatch: 0/147\tEpoch: 3/6\tTraining Loss: 0.2436\n",
      "Elapsed time: 1.23 hours\tBatch: 1/147\tEpoch: 3/6\tTraining Loss: 0.1960\n",
      "Elapsed time: 1.23 hours\tBatch: 2/147\tEpoch: 3/6\tTraining Loss: 0.2341\n",
      "Elapsed time: 1.24 hours\tBatch: 3/147\tEpoch: 3/6\tTraining Loss: 0.2191\n",
      "Elapsed time: 1.24 hours\tBatch: 4/147\tEpoch: 3/6\tTraining Loss: 0.2430\n",
      "Elapsed time: 1.24 hours\tBatch: 5/147\tEpoch: 3/6\tTraining Loss: 0.2554\n",
      "Elapsed time: 1.25 hours\tBatch: 6/147\tEpoch: 3/6\tTraining Loss: 0.1984\n",
      "Elapsed time: 1.25 hours\tBatch: 7/147\tEpoch: 3/6\tTraining Loss: 0.2066\n",
      "Elapsed time: 1.25 hours\tBatch: 8/147\tEpoch: 3/6\tTraining Loss: 0.2444\n",
      "Elapsed time: 1.26 hours\tBatch: 9/147\tEpoch: 3/6\tTraining Loss: 0.2315\n",
      "Elapsed time: 1.26 hours\tBatch: 10/147\tEpoch: 3/6\tTraining Loss: 0.2441\n",
      "Elapsed time: 1.26 hours\tBatch: 11/147\tEpoch: 3/6\tTraining Loss: 0.2440\n",
      "Elapsed time: 1.27 hours\tBatch: 12/147\tEpoch: 3/6\tTraining Loss: 0.1970\n",
      "Elapsed time: 1.27 hours\tBatch: 13/147\tEpoch: 3/6\tTraining Loss: 0.2313\n",
      "Elapsed time: 1.27 hours\tBatch: 14/147\tEpoch: 3/6\tTraining Loss: 0.2348\n",
      "Elapsed time: 1.28 hours\tBatch: 15/147\tEpoch: 3/6\tTraining Loss: 0.2441\n",
      "Elapsed time: 1.28 hours\tBatch: 16/147\tEpoch: 3/6\tTraining Loss: 0.2082\n",
      "Elapsed time: 1.28 hours\tBatch: 17/147\tEpoch: 3/6\tTraining Loss: 0.1988\n",
      "Elapsed time: 1.29 hours\tBatch: 18/147\tEpoch: 3/6\tTraining Loss: 0.2078\n",
      "Elapsed time: 1.29 hours\tBatch: 19/147\tEpoch: 3/6\tTraining Loss: 0.2330\n",
      "Elapsed time: 1.29 hours\tBatch: 20/147\tEpoch: 3/6\tTraining Loss: 0.2346\n",
      "Elapsed time: 1.30 hours\tBatch: 21/147\tEpoch: 3/6\tTraining Loss: 0.2336\n",
      "Elapsed time: 1.30 hours\tBatch: 22/147\tEpoch: 3/6\tTraining Loss: 0.2379\n",
      "Elapsed time: 1.30 hours\tBatch: 23/147\tEpoch: 3/6\tTraining Loss: 0.2158\n",
      "Elapsed time: 1.31 hours\tBatch: 24/147\tEpoch: 3/6\tTraining Loss: 0.1899\n",
      "Elapsed time: 1.31 hours\tBatch: 25/147\tEpoch: 3/6\tTraining Loss: 0.2328\n",
      "Elapsed time: 1.31 hours\tBatch: 26/147\tEpoch: 3/6\tTraining Loss: 0.2058\n",
      "Elapsed time: 1.32 hours\tBatch: 27/147\tEpoch: 3/6\tTraining Loss: 0.2795\n",
      "Elapsed time: 1.32 hours\tBatch: 28/147\tEpoch: 3/6\tTraining Loss: 0.2241\n",
      "Elapsed time: 1.32 hours\tBatch: 29/147\tEpoch: 3/6\tTraining Loss: 0.2046\n",
      "Elapsed time: 1.33 hours\tBatch: 30/147\tEpoch: 3/6\tTraining Loss: 0.2539\n",
      "Elapsed time: 1.33 hours\tBatch: 31/147\tEpoch: 3/6\tTraining Loss: 0.2240\n",
      "Elapsed time: 1.33 hours\tBatch: 32/147\tEpoch: 3/6\tTraining Loss: 0.2270\n",
      "Elapsed time: 1.34 hours\tBatch: 33/147\tEpoch: 3/6\tTraining Loss: 0.1958\n",
      "Elapsed time: 1.34 hours\tBatch: 34/147\tEpoch: 3/6\tTraining Loss: 0.2318\n",
      "Elapsed time: 1.34 hours\tBatch: 35/147\tEpoch: 3/6\tTraining Loss: 0.2095\n",
      "Elapsed time: 1.35 hours\tBatch: 36/147\tEpoch: 3/6\tTraining Loss: 0.2506\n",
      "Elapsed time: 1.35 hours\tBatch: 37/147\tEpoch: 3/6\tTraining Loss: 0.2273\n",
      "Elapsed time: 1.35 hours\tBatch: 38/147\tEpoch: 3/6\tTraining Loss: 0.2110\n",
      "Elapsed time: 1.36 hours\tBatch: 39/147\tEpoch: 3/6\tTraining Loss: 0.2154\n",
      "Elapsed time: 1.36 hours\tBatch: 40/147\tEpoch: 3/6\tTraining Loss: 0.1959\n",
      "Elapsed time: 1.36 hours\tBatch: 41/147\tEpoch: 3/6\tTraining Loss: 0.2301\n",
      "Elapsed time: 1.37 hours\tBatch: 42/147\tEpoch: 3/6\tTraining Loss: 0.2060\n",
      "Elapsed time: 1.37 hours\tBatch: 43/147\tEpoch: 3/6\tTraining Loss: 0.2176\n",
      "Elapsed time: 1.37 hours\tBatch: 44/147\tEpoch: 3/6\tTraining Loss: 0.2476\n",
      "Elapsed time: 1.38 hours\tBatch: 45/147\tEpoch: 3/6\tTraining Loss: 0.2106\n",
      "Elapsed time: 1.38 hours\tBatch: 46/147\tEpoch: 3/6\tTraining Loss: 0.2747\n",
      "Elapsed time: 1.38 hours\tBatch: 47/147\tEpoch: 3/6\tTraining Loss: 0.2075\n",
      "Elapsed time: 1.39 hours\tBatch: 48/147\tEpoch: 3/6\tTraining Loss: 0.2739\n",
      "Elapsed time: 1.39 hours\tBatch: 49/147\tEpoch: 3/6\tTraining Loss: 0.2319\n",
      "Elapsed time: 1.39 hours\tBatch: 50/147\tEpoch: 3/6\tTraining Loss: 0.2500\n",
      "Elapsed time: 1.40 hours\tBatch: 51/147\tEpoch: 3/6\tTraining Loss: 0.2117\n",
      "Elapsed time: 1.40 hours\tBatch: 52/147\tEpoch: 3/6\tTraining Loss: 0.2127\n",
      "Elapsed time: 1.40 hours\tBatch: 53/147\tEpoch: 3/6\tTraining Loss: 0.2186\n",
      "Elapsed time: 1.41 hours\tBatch: 54/147\tEpoch: 3/6\tTraining Loss: 0.2291\n",
      "Elapsed time: 1.41 hours\tBatch: 55/147\tEpoch: 3/6\tTraining Loss: 0.1999\n",
      "Elapsed time: 1.41 hours\tBatch: 56/147\tEpoch: 3/6\tTraining Loss: 0.2343\n",
      "Elapsed time: 1.42 hours\tBatch: 57/147\tEpoch: 3/6\tTraining Loss: 0.2252\n",
      "Elapsed time: 1.42 hours\tBatch: 58/147\tEpoch: 3/6\tTraining Loss: 0.2507\n",
      "Elapsed time: 1.42 hours\tBatch: 59/147\tEpoch: 3/6\tTraining Loss: 0.2337\n",
      "Elapsed time: 1.43 hours\tBatch: 60/147\tEpoch: 3/6\tTraining Loss: 0.2027\n",
      "Elapsed time: 1.43 hours\tBatch: 61/147\tEpoch: 3/6\tTraining Loss: 0.2307\n",
      "Elapsed time: 1.43 hours\tBatch: 62/147\tEpoch: 3/6\tTraining Loss: 0.2171\n",
      "Elapsed time: 1.44 hours\tBatch: 63/147\tEpoch: 3/6\tTraining Loss: 0.2212\n",
      "Elapsed time: 1.44 hours\tBatch: 64/147\tEpoch: 3/6\tTraining Loss: 0.2711\n",
      "Elapsed time: 1.44 hours\tBatch: 65/147\tEpoch: 3/6\tTraining Loss: 0.2451\n",
      "Elapsed time: 1.45 hours\tBatch: 66/147\tEpoch: 3/6\tTraining Loss: 0.2473\n",
      "Elapsed time: 1.45 hours\tBatch: 67/147\tEpoch: 3/6\tTraining Loss: 0.2509\n",
      "Elapsed time: 1.45 hours\tBatch: 68/147\tEpoch: 3/6\tTraining Loss: 0.1995\n",
      "Elapsed time: 1.46 hours\tBatch: 69/147\tEpoch: 3/6\tTraining Loss: 0.2181\n",
      "Elapsed time: 1.46 hours\tBatch: 70/147\tEpoch: 3/6\tTraining Loss: 0.2160\n",
      "Elapsed time: 1.46 hours\tBatch: 71/147\tEpoch: 3/6\tTraining Loss: 0.2135\n",
      "Elapsed time: 1.47 hours\tBatch: 72/147\tEpoch: 3/6\tTraining Loss: 0.2501\n",
      "Elapsed time: 1.47 hours\tBatch: 73/147\tEpoch: 3/6\tTraining Loss: 0.2012\n",
      "Elapsed time: 1.47 hours\tBatch: 74/147\tEpoch: 3/6\tTraining Loss: 0.2173\n",
      "Elapsed time: 1.48 hours\tBatch: 75/147\tEpoch: 3/6\tTraining Loss: 0.2445\n",
      "Elapsed time: 1.48 hours\tBatch: 76/147\tEpoch: 3/6\tTraining Loss: 0.2246\n",
      "Elapsed time: 1.48 hours\tBatch: 77/147\tEpoch: 3/6\tTraining Loss: 0.2393\n",
      "Elapsed time: 1.49 hours\tBatch: 78/147\tEpoch: 3/6\tTraining Loss: 0.2151\n",
      "Elapsed time: 1.49 hours\tBatch: 79/147\tEpoch: 3/6\tTraining Loss: 0.2315\n",
      "Elapsed time: 1.49 hours\tBatch: 80/147\tEpoch: 3/6\tTraining Loss: 0.2396\n",
      "Elapsed time: 1.50 hours\tBatch: 81/147\tEpoch: 3/6\tTraining Loss: 0.2163\n",
      "Elapsed time: 1.50 hours\tBatch: 82/147\tEpoch: 3/6\tTraining Loss: 0.1947\n",
      "Elapsed time: 1.50 hours\tBatch: 83/147\tEpoch: 3/6\tTraining Loss: 0.2305\n",
      "Elapsed time: 1.51 hours\tBatch: 84/147\tEpoch: 3/6\tTraining Loss: 0.2244\n",
      "Elapsed time: 1.51 hours\tBatch: 85/147\tEpoch: 3/6\tTraining Loss: 0.1953\n",
      "Elapsed time: 1.52 hours\tBatch: 86/147\tEpoch: 3/6\tTraining Loss: 0.2405\n",
      "Elapsed time: 1.52 hours\tBatch: 87/147\tEpoch: 3/6\tTraining Loss: 0.2179\n",
      "Elapsed time: 1.52 hours\tBatch: 88/147\tEpoch: 3/6\tTraining Loss: 0.2463\n",
      "Elapsed time: 1.53 hours\tBatch: 89/147\tEpoch: 3/6\tTraining Loss: 0.2571\n",
      "Elapsed time: 1.53 hours\tBatch: 90/147\tEpoch: 3/6\tTraining Loss: 0.2138\n",
      "Elapsed time: 1.53 hours\tBatch: 91/147\tEpoch: 3/6\tTraining Loss: 0.2125\n",
      "Elapsed time: 1.54 hours\tBatch: 92/147\tEpoch: 3/6\tTraining Loss: 0.2154\n",
      "Elapsed time: 1.54 hours\tBatch: 93/147\tEpoch: 3/6\tTraining Loss: 0.2578\n",
      "Elapsed time: 1.54 hours\tBatch: 94/147\tEpoch: 3/6\tTraining Loss: 0.1909\n",
      "Elapsed time: 1.55 hours\tBatch: 95/147\tEpoch: 3/6\tTraining Loss: 0.2136\n",
      "Elapsed time: 1.55 hours\tBatch: 96/147\tEpoch: 3/6\tTraining Loss: 0.2052\n",
      "Elapsed time: 1.55 hours\tBatch: 97/147\tEpoch: 3/6\tTraining Loss: 0.2362\n",
      "Elapsed time: 1.56 hours\tBatch: 98/147\tEpoch: 3/6\tTraining Loss: 0.2021\n",
      "Elapsed time: 1.56 hours\tBatch: 99/147\tEpoch: 3/6\tTraining Loss: 0.2367\n",
      "Elapsed time: 1.56 hours\tBatch: 100/147\tEpoch: 3/6\tTraining Loss: 0.2117\n",
      "Elapsed time: 1.57 hours\tBatch: 101/147\tEpoch: 3/6\tTraining Loss: 0.2126\n",
      "Elapsed time: 1.57 hours\tBatch: 102/147\tEpoch: 3/6\tTraining Loss: 0.2160\n",
      "Elapsed time: 1.57 hours\tBatch: 103/147\tEpoch: 3/6\tTraining Loss: 0.2463\n",
      "Elapsed time: 1.58 hours\tBatch: 104/147\tEpoch: 3/6\tTraining Loss: 0.2325\n",
      "Elapsed time: 1.58 hours\tBatch: 105/147\tEpoch: 3/6\tTraining Loss: 0.2191\n",
      "Elapsed time: 1.58 hours\tBatch: 106/147\tEpoch: 3/6\tTraining Loss: 0.2224\n",
      "Elapsed time: 1.59 hours\tBatch: 107/147\tEpoch: 3/6\tTraining Loss: 0.2426\n",
      "Elapsed time: 1.59 hours\tBatch: 108/147\tEpoch: 3/6\tTraining Loss: 0.2069\n",
      "Elapsed time: 1.59 hours\tBatch: 109/147\tEpoch: 3/6\tTraining Loss: 0.2256\n",
      "Elapsed time: 1.60 hours\tBatch: 110/147\tEpoch: 3/6\tTraining Loss: 0.2060\n",
      "Elapsed time: 1.60 hours\tBatch: 111/147\tEpoch: 3/6\tTraining Loss: 0.2585\n",
      "Elapsed time: 1.60 hours\tBatch: 112/147\tEpoch: 3/6\tTraining Loss: 0.2496\n",
      "Elapsed time: 1.61 hours\tBatch: 113/147\tEpoch: 3/6\tTraining Loss: 0.2439\n",
      "Elapsed time: 1.61 hours\tBatch: 114/147\tEpoch: 3/6\tTraining Loss: 0.2133\n",
      "Elapsed time: 1.61 hours\tBatch: 115/147\tEpoch: 3/6\tTraining Loss: 0.2198\n",
      "Elapsed time: 1.62 hours\tBatch: 116/147\tEpoch: 3/6\tTraining Loss: 0.2346\n",
      "Elapsed time: 1.62 hours\tBatch: 117/147\tEpoch: 3/6\tTraining Loss: 0.2565\n",
      "Elapsed time: 1.63 hours\tBatch: 118/147\tEpoch: 3/6\tTraining Loss: 0.2313\n",
      "Elapsed time: 1.63 hours\tBatch: 119/147\tEpoch: 3/6\tTraining Loss: 0.2125\n",
      "Elapsed time: 1.63 hours\tBatch: 120/147\tEpoch: 3/6\tTraining Loss: 0.2287\n",
      "Elapsed time: 1.64 hours\tBatch: 121/147\tEpoch: 3/6\tTraining Loss: 0.2087\n",
      "Elapsed time: 1.64 hours\tBatch: 122/147\tEpoch: 3/6\tTraining Loss: 0.2248\n",
      "Elapsed time: 1.64 hours\tBatch: 123/147\tEpoch: 3/6\tTraining Loss: 0.2079\n",
      "Elapsed time: 1.65 hours\tBatch: 124/147\tEpoch: 3/6\tTraining Loss: 0.1999\n",
      "Elapsed time: 1.65 hours\tBatch: 125/147\tEpoch: 3/6\tTraining Loss: 0.2102\n",
      "Elapsed time: 1.65 hours\tBatch: 126/147\tEpoch: 3/6\tTraining Loss: 0.2298\n",
      "Elapsed time: 1.66 hours\tBatch: 127/147\tEpoch: 3/6\tTraining Loss: 0.2301\n",
      "Elapsed time: 1.66 hours\tBatch: 128/147\tEpoch: 3/6\tTraining Loss: 0.2201\n",
      "Elapsed time: 1.66 hours\tBatch: 129/147\tEpoch: 3/6\tTraining Loss: 0.2143\n",
      "Elapsed time: 1.67 hours\tBatch: 130/147\tEpoch: 3/6\tTraining Loss: 0.2193\n",
      "Elapsed time: 1.67 hours\tBatch: 131/147\tEpoch: 3/6\tTraining Loss: 0.2437\n",
      "Elapsed time: 1.67 hours\tBatch: 132/147\tEpoch: 3/6\tTraining Loss: 0.2700\n",
      "Elapsed time: 1.68 hours\tBatch: 133/147\tEpoch: 3/6\tTraining Loss: 0.2230\n",
      "Elapsed time: 1.68 hours\tBatch: 134/147\tEpoch: 3/6\tTraining Loss: 0.2286\n",
      "Elapsed time: 1.68 hours\tBatch: 135/147\tEpoch: 3/6\tTraining Loss: 0.2577\n",
      "Elapsed time: 1.69 hours\tBatch: 136/147\tEpoch: 3/6\tTraining Loss: 0.2014\n",
      "Elapsed time: 1.69 hours\tBatch: 137/147\tEpoch: 3/6\tTraining Loss: 0.2220\n",
      "Elapsed time: 1.70 hours\tBatch: 138/147\tEpoch: 3/6\tTraining Loss: 0.2035\n",
      "Elapsed time: 1.70 hours\tBatch: 139/147\tEpoch: 3/6\tTraining Loss: 0.2373\n",
      "Elapsed time: 1.70 hours\tBatch: 140/147\tEpoch: 3/6\tTraining Loss: 0.2341\n",
      "Elapsed time: 1.71 hours\tBatch: 141/147\tEpoch: 3/6\tTraining Loss: 0.1975\n",
      "Elapsed time: 1.71 hours\tBatch: 142/147\tEpoch: 3/6\tTraining Loss: 0.2693\n",
      "Elapsed time: 1.71 hours\tBatch: 143/147\tEpoch: 3/6\tTraining Loss: 0.2114\n",
      "Elapsed time: 1.72 hours\tBatch: 144/147\tEpoch: 3/6\tTraining Loss: 0.2359\n",
      "Elapsed time: 1.72 hours\tBatch: 145/147\tEpoch: 3/6\tTraining Loss: 0.2193\n",
      "Elapsed time: 1.72 hours\tBatch: 146/147\tEpoch: 3/6\tTraining Loss: 0.2325\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Saving model...\n",
      "Model weights saved at \"rn_model.pt\"\n",
      "Validation loss for epoch 3: 0.1853\n",
      "Learning rate set to 1e-06\n",
      "Elapsed time: 1.85 hours\tBatch: 0/147\tEpoch: 4/6\tTraining Loss: 0.2174\n",
      "Elapsed time: 1.85 hours\tBatch: 1/147\tEpoch: 4/6\tTraining Loss: 0.2265\n",
      "Elapsed time: 1.86 hours\tBatch: 2/147\tEpoch: 4/6\tTraining Loss: 0.2457\n",
      "Elapsed time: 1.86 hours\tBatch: 3/147\tEpoch: 4/6\tTraining Loss: 0.2049\n",
      "Elapsed time: 1.87 hours\tBatch: 4/147\tEpoch: 4/6\tTraining Loss: 0.2636\n",
      "Elapsed time: 1.87 hours\tBatch: 5/147\tEpoch: 4/6\tTraining Loss: 0.2015\n",
      "Elapsed time: 1.87 hours\tBatch: 6/147\tEpoch: 4/6\tTraining Loss: 0.2426\n",
      "Elapsed time: 1.88 hours\tBatch: 7/147\tEpoch: 4/6\tTraining Loss: 0.2131\n",
      "Elapsed time: 1.88 hours\tBatch: 8/147\tEpoch: 4/6\tTraining Loss: 0.2233\n",
      "Elapsed time: 1.88 hours\tBatch: 9/147\tEpoch: 4/6\tTraining Loss: 0.2170\n",
      "Elapsed time: 1.89 hours\tBatch: 10/147\tEpoch: 4/6\tTraining Loss: 0.2328\n",
      "Elapsed time: 1.89 hours\tBatch: 11/147\tEpoch: 4/6\tTraining Loss: 0.2148\n",
      "Elapsed time: 1.89 hours\tBatch: 12/147\tEpoch: 4/6\tTraining Loss: 0.2308\n",
      "Elapsed time: 1.90 hours\tBatch: 13/147\tEpoch: 4/6\tTraining Loss: 0.2282\n",
      "Elapsed time: 1.90 hours\tBatch: 14/147\tEpoch: 4/6\tTraining Loss: 0.2156\n",
      "Elapsed time: 1.91 hours\tBatch: 15/147\tEpoch: 4/6\tTraining Loss: 0.2041\n",
      "Elapsed time: 1.91 hours\tBatch: 16/147\tEpoch: 4/6\tTraining Loss: 0.2103\n",
      "Elapsed time: 1.91 hours\tBatch: 17/147\tEpoch: 4/6\tTraining Loss: 0.2238\n",
      "Elapsed time: 1.92 hours\tBatch: 18/147\tEpoch: 4/6\tTraining Loss: 0.2375\n",
      "Elapsed time: 1.92 hours\tBatch: 19/147\tEpoch: 4/6\tTraining Loss: 0.2148\n",
      "Elapsed time: 1.92 hours\tBatch: 20/147\tEpoch: 4/6\tTraining Loss: 0.2295\n",
      "Elapsed time: 1.93 hours\tBatch: 21/147\tEpoch: 4/6\tTraining Loss: 0.2379\n",
      "Elapsed time: 1.93 hours\tBatch: 22/147\tEpoch: 4/6\tTraining Loss: 0.1964\n",
      "Elapsed time: 1.93 hours\tBatch: 23/147\tEpoch: 4/6\tTraining Loss: 0.2519\n",
      "Elapsed time: 1.94 hours\tBatch: 24/147\tEpoch: 4/6\tTraining Loss: 0.2266\n",
      "Elapsed time: 1.94 hours\tBatch: 25/147\tEpoch: 4/6\tTraining Loss: 0.2312\n",
      "Elapsed time: 1.94 hours\tBatch: 26/147\tEpoch: 4/6\tTraining Loss: 0.2346\n",
      "Elapsed time: 1.95 hours\tBatch: 27/147\tEpoch: 4/6\tTraining Loss: 0.2207\n",
      "Elapsed time: 1.95 hours\tBatch: 28/147\tEpoch: 4/6\tTraining Loss: 0.2150\n",
      "Elapsed time: 1.96 hours\tBatch: 29/147\tEpoch: 4/6\tTraining Loss: 0.2528\n",
      "Elapsed time: 1.96 hours\tBatch: 30/147\tEpoch: 4/6\tTraining Loss: 0.1969\n",
      "Elapsed time: 1.96 hours\tBatch: 31/147\tEpoch: 4/6\tTraining Loss: 0.2579\n",
      "Elapsed time: 1.97 hours\tBatch: 32/147\tEpoch: 4/6\tTraining Loss: 0.2261\n",
      "Elapsed time: 1.97 hours\tBatch: 33/147\tEpoch: 4/6\tTraining Loss: 0.2423\n",
      "Elapsed time: 1.97 hours\tBatch: 34/147\tEpoch: 4/6\tTraining Loss: 0.2440\n",
      "Elapsed time: 1.98 hours\tBatch: 35/147\tEpoch: 4/6\tTraining Loss: 0.1884\n",
      "Elapsed time: 1.98 hours\tBatch: 36/147\tEpoch: 4/6\tTraining Loss: 0.1952\n",
      "Elapsed time: 1.98 hours\tBatch: 37/147\tEpoch: 4/6\tTraining Loss: 0.2367\n",
      "Elapsed time: 1.99 hours\tBatch: 38/147\tEpoch: 4/6\tTraining Loss: 0.2732\n",
      "Elapsed time: 1.99 hours\tBatch: 39/147\tEpoch: 4/6\tTraining Loss: 0.2790\n",
      "Elapsed time: 1.99 hours\tBatch: 40/147\tEpoch: 4/6\tTraining Loss: 0.2216\n",
      "Elapsed time: 2.00 hours\tBatch: 41/147\tEpoch: 4/6\tTraining Loss: 0.2299\n",
      "Elapsed time: 2.00 hours\tBatch: 42/147\tEpoch: 4/6\tTraining Loss: 0.2780\n",
      "Elapsed time: 2.00 hours\tBatch: 43/147\tEpoch: 4/6\tTraining Loss: 0.2028\n",
      "Elapsed time: 2.01 hours\tBatch: 44/147\tEpoch: 4/6\tTraining Loss: 0.2157\n",
      "Elapsed time: 2.01 hours\tBatch: 45/147\tEpoch: 4/6\tTraining Loss: 0.2402\n",
      "Elapsed time: 2.02 hours\tBatch: 46/147\tEpoch: 4/6\tTraining Loss: 0.2029\n",
      "Elapsed time: 2.02 hours\tBatch: 47/147\tEpoch: 4/6\tTraining Loss: 0.1979\n",
      "Elapsed time: 2.02 hours\tBatch: 48/147\tEpoch: 4/6\tTraining Loss: 0.2248\n",
      "Elapsed time: 2.03 hours\tBatch: 49/147\tEpoch: 4/6\tTraining Loss: 0.2151\n",
      "Elapsed time: 2.03 hours\tBatch: 50/147\tEpoch: 4/6\tTraining Loss: 0.2031\n",
      "Elapsed time: 2.03 hours\tBatch: 51/147\tEpoch: 4/6\tTraining Loss: 0.2169\n",
      "Elapsed time: 2.04 hours\tBatch: 52/147\tEpoch: 4/6\tTraining Loss: 0.2164\n",
      "Elapsed time: 2.04 hours\tBatch: 53/147\tEpoch: 4/6\tTraining Loss: 0.2076\n",
      "Elapsed time: 2.04 hours\tBatch: 54/147\tEpoch: 4/6\tTraining Loss: 0.2106\n",
      "Elapsed time: 2.05 hours\tBatch: 55/147\tEpoch: 4/6\tTraining Loss: 0.2037\n",
      "Elapsed time: 2.05 hours\tBatch: 56/147\tEpoch: 4/6\tTraining Loss: 0.1847\n",
      "Elapsed time: 2.05 hours\tBatch: 57/147\tEpoch: 4/6\tTraining Loss: 0.2100\n",
      "Elapsed time: 2.06 hours\tBatch: 58/147\tEpoch: 4/6\tTraining Loss: 0.2300\n",
      "Elapsed time: 2.06 hours\tBatch: 59/147\tEpoch: 4/6\tTraining Loss: 0.2410\n",
      "Elapsed time: 2.06 hours\tBatch: 60/147\tEpoch: 4/6\tTraining Loss: 0.2116\n",
      "Elapsed time: 2.07 hours\tBatch: 61/147\tEpoch: 4/6\tTraining Loss: 0.2173\n",
      "Elapsed time: 2.07 hours\tBatch: 62/147\tEpoch: 4/6\tTraining Loss: 0.2254\n",
      "Elapsed time: 2.07 hours\tBatch: 63/147\tEpoch: 4/6\tTraining Loss: 0.2102\n",
      "Elapsed time: 2.08 hours\tBatch: 64/147\tEpoch: 4/6\tTraining Loss: 0.2251\n",
      "Elapsed time: 2.08 hours\tBatch: 65/147\tEpoch: 4/6\tTraining Loss: 0.2007\n",
      "Elapsed time: 2.09 hours\tBatch: 66/147\tEpoch: 4/6\tTraining Loss: 0.2264\n",
      "Elapsed time: 2.09 hours\tBatch: 67/147\tEpoch: 4/6\tTraining Loss: 0.2098\n",
      "Elapsed time: 2.09 hours\tBatch: 68/147\tEpoch: 4/6\tTraining Loss: 0.2137\n",
      "Elapsed time: 2.10 hours\tBatch: 69/147\tEpoch: 4/6\tTraining Loss: 0.2236\n",
      "Elapsed time: 2.10 hours\tBatch: 70/147\tEpoch: 4/6\tTraining Loss: 0.2010\n",
      "Elapsed time: 2.10 hours\tBatch: 71/147\tEpoch: 4/6\tTraining Loss: 0.2165\n",
      "Elapsed time: 2.11 hours\tBatch: 72/147\tEpoch: 4/6\tTraining Loss: 0.2344\n",
      "Elapsed time: 2.11 hours\tBatch: 73/147\tEpoch: 4/6\tTraining Loss: 0.2399\n",
      "Elapsed time: 2.11 hours\tBatch: 74/147\tEpoch: 4/6\tTraining Loss: 0.2017\n",
      "Elapsed time: 2.12 hours\tBatch: 75/147\tEpoch: 4/6\tTraining Loss: 0.2385\n",
      "Elapsed time: 2.12 hours\tBatch: 76/147\tEpoch: 4/6\tTraining Loss: 0.1725\n",
      "Elapsed time: 2.12 hours\tBatch: 77/147\tEpoch: 4/6\tTraining Loss: 0.1873\n",
      "Elapsed time: 2.13 hours\tBatch: 78/147\tEpoch: 4/6\tTraining Loss: 0.2289\n",
      "Elapsed time: 2.13 hours\tBatch: 79/147\tEpoch: 4/6\tTraining Loss: 0.2068\n",
      "Elapsed time: 2.13 hours\tBatch: 80/147\tEpoch: 4/6\tTraining Loss: 0.1937\n",
      "Elapsed time: 2.14 hours\tBatch: 81/147\tEpoch: 4/6\tTraining Loss: 0.2232\n",
      "Elapsed time: 2.14 hours\tBatch: 82/147\tEpoch: 4/6\tTraining Loss: 0.2081\n",
      "Elapsed time: 2.14 hours\tBatch: 83/147\tEpoch: 4/6\tTraining Loss: 0.2012\n",
      "Elapsed time: 2.15 hours\tBatch: 84/147\tEpoch: 4/6\tTraining Loss: 0.2501\n",
      "Elapsed time: 2.15 hours\tBatch: 85/147\tEpoch: 4/6\tTraining Loss: 0.2394\n",
      "Elapsed time: 2.15 hours\tBatch: 86/147\tEpoch: 4/6\tTraining Loss: 0.2160\n",
      "Elapsed time: 2.16 hours\tBatch: 87/147\tEpoch: 4/6\tTraining Loss: 0.2413\n",
      "Elapsed time: 2.16 hours\tBatch: 88/147\tEpoch: 4/6\tTraining Loss: 0.2180\n",
      "Elapsed time: 2.17 hours\tBatch: 89/147\tEpoch: 4/6\tTraining Loss: 0.2171\n",
      "Elapsed time: 2.17 hours\tBatch: 90/147\tEpoch: 4/6\tTraining Loss: 0.2268\n",
      "Elapsed time: 2.17 hours\tBatch: 91/147\tEpoch: 4/6\tTraining Loss: 0.2558\n",
      "Elapsed time: 2.18 hours\tBatch: 92/147\tEpoch: 4/6\tTraining Loss: 0.2300\n",
      "Elapsed time: 2.18 hours\tBatch: 93/147\tEpoch: 4/6\tTraining Loss: 0.2355\n",
      "Elapsed time: 2.18 hours\tBatch: 94/147\tEpoch: 4/6\tTraining Loss: 0.2184\n",
      "Elapsed time: 2.19 hours\tBatch: 95/147\tEpoch: 4/6\tTraining Loss: 0.2490\n",
      "Elapsed time: 2.19 hours\tBatch: 96/147\tEpoch: 4/6\tTraining Loss: 0.2769\n",
      "Elapsed time: 2.19 hours\tBatch: 97/147\tEpoch: 4/6\tTraining Loss: 0.1922\n",
      "Elapsed time: 2.20 hours\tBatch: 98/147\tEpoch: 4/6\tTraining Loss: 0.2479\n",
      "Elapsed time: 2.20 hours\tBatch: 99/147\tEpoch: 4/6\tTraining Loss: 0.2228\n",
      "Elapsed time: 2.20 hours\tBatch: 100/147\tEpoch: 4/6\tTraining Loss: 0.2169\n",
      "Elapsed time: 2.21 hours\tBatch: 101/147\tEpoch: 4/6\tTraining Loss: 0.2161\n",
      "Elapsed time: 2.21 hours\tBatch: 102/147\tEpoch: 4/6\tTraining Loss: 0.2521\n",
      "Elapsed time: 2.21 hours\tBatch: 103/147\tEpoch: 4/6\tTraining Loss: 0.2212\n",
      "Elapsed time: 2.22 hours\tBatch: 104/147\tEpoch: 4/6\tTraining Loss: 0.2245\n",
      "Elapsed time: 2.22 hours\tBatch: 105/147\tEpoch: 4/6\tTraining Loss: 0.2571\n",
      "Elapsed time: 2.22 hours\tBatch: 106/147\tEpoch: 4/6\tTraining Loss: 0.2331\n",
      "Elapsed time: 2.23 hours\tBatch: 107/147\tEpoch: 4/6\tTraining Loss: 0.2328\n",
      "Elapsed time: 2.23 hours\tBatch: 108/147\tEpoch: 4/6\tTraining Loss: 0.2224\n",
      "Elapsed time: 2.23 hours\tBatch: 109/147\tEpoch: 4/6\tTraining Loss: 0.1964\n",
      "Elapsed time: 2.24 hours\tBatch: 110/147\tEpoch: 4/6\tTraining Loss: 0.2232\n",
      "Elapsed time: 2.24 hours\tBatch: 111/147\tEpoch: 4/6\tTraining Loss: 0.1970\n",
      "Elapsed time: 2.25 hours\tBatch: 112/147\tEpoch: 4/6\tTraining Loss: 0.2484\n",
      "Elapsed time: 2.25 hours\tBatch: 113/147\tEpoch: 4/6\tTraining Loss: 0.2274\n",
      "Elapsed time: 2.25 hours\tBatch: 114/147\tEpoch: 4/6\tTraining Loss: 0.2206\n",
      "Elapsed time: 2.26 hours\tBatch: 115/147\tEpoch: 4/6\tTraining Loss: 0.2450\n",
      "Elapsed time: 2.26 hours\tBatch: 116/147\tEpoch: 4/6\tTraining Loss: 0.2087\n",
      "Elapsed time: 2.26 hours\tBatch: 117/147\tEpoch: 4/6\tTraining Loss: 0.2329\n",
      "Elapsed time: 2.27 hours\tBatch: 118/147\tEpoch: 4/6\tTraining Loss: 0.2379\n",
      "Elapsed time: 2.27 hours\tBatch: 119/147\tEpoch: 4/6\tTraining Loss: 0.1996\n",
      "Elapsed time: 2.27 hours\tBatch: 120/147\tEpoch: 4/6\tTraining Loss: 0.2358\n",
      "Elapsed time: 2.28 hours\tBatch: 121/147\tEpoch: 4/6\tTraining Loss: 0.2067\n",
      "Elapsed time: 2.28 hours\tBatch: 122/147\tEpoch: 4/6\tTraining Loss: 0.2278\n",
      "Elapsed time: 2.28 hours\tBatch: 123/147\tEpoch: 4/6\tTraining Loss: 0.2041\n",
      "Elapsed time: 2.29 hours\tBatch: 124/147\tEpoch: 4/6\tTraining Loss: 0.2194\n",
      "Elapsed time: 2.29 hours\tBatch: 125/147\tEpoch: 4/6\tTraining Loss: 0.2235\n",
      "Elapsed time: 2.30 hours\tBatch: 126/147\tEpoch: 4/6\tTraining Loss: 0.2066\n",
      "Elapsed time: 2.30 hours\tBatch: 127/147\tEpoch: 4/6\tTraining Loss: 0.2042\n",
      "Elapsed time: 2.30 hours\tBatch: 128/147\tEpoch: 4/6\tTraining Loss: 0.2273\n",
      "Elapsed time: 2.31 hours\tBatch: 129/147\tEpoch: 4/6\tTraining Loss: 0.2107\n",
      "Elapsed time: 2.31 hours\tBatch: 130/147\tEpoch: 4/6\tTraining Loss: 0.2038\n",
      "Elapsed time: 2.31 hours\tBatch: 131/147\tEpoch: 4/6\tTraining Loss: 0.2160\n",
      "Elapsed time: 2.32 hours\tBatch: 132/147\tEpoch: 4/6\tTraining Loss: 0.1722\n",
      "Elapsed time: 2.32 hours\tBatch: 133/147\tEpoch: 4/6\tTraining Loss: 0.2541\n",
      "Elapsed time: 2.32 hours\tBatch: 134/147\tEpoch: 4/6\tTraining Loss: 0.2151\n",
      "Elapsed time: 2.33 hours\tBatch: 135/147\tEpoch: 4/6\tTraining Loss: 0.2630\n",
      "Elapsed time: 2.33 hours\tBatch: 136/147\tEpoch: 4/6\tTraining Loss: 0.2366\n",
      "Elapsed time: 2.33 hours\tBatch: 137/147\tEpoch: 4/6\tTraining Loss: 0.2065\n",
      "Elapsed time: 2.34 hours\tBatch: 138/147\tEpoch: 4/6\tTraining Loss: 0.2315\n",
      "Elapsed time: 2.34 hours\tBatch: 139/147\tEpoch: 4/6\tTraining Loss: 0.2354\n",
      "Elapsed time: 2.35 hours\tBatch: 140/147\tEpoch: 4/6\tTraining Loss: 0.2542\n",
      "Elapsed time: 2.35 hours\tBatch: 141/147\tEpoch: 4/6\tTraining Loss: 0.2341\n",
      "Elapsed time: 2.35 hours\tBatch: 142/147\tEpoch: 4/6\tTraining Loss: 0.2346\n",
      "Elapsed time: 2.36 hours\tBatch: 143/147\tEpoch: 4/6\tTraining Loss: 0.2248\n",
      "Elapsed time: 2.36 hours\tBatch: 144/147\tEpoch: 4/6\tTraining Loss: 0.2259\n",
      "Elapsed time: 2.36 hours\tBatch: 145/147\tEpoch: 4/6\tTraining Loss: 0.1942\n",
      "Elapsed time: 2.37 hours\tBatch: 146/147\tEpoch: 4/6\tTraining Loss: 0.2409\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Validation loss for epoch 4: 0.1854\n",
      "Learning rate set to 1.0000000000000001e-07\n",
      "Elapsed time: 2.50 hours\tBatch: 0/147\tEpoch: 5/6\tTraining Loss: 0.2636\n",
      "Elapsed time: 2.50 hours\tBatch: 1/147\tEpoch: 5/6\tTraining Loss: 0.2260\n",
      "Elapsed time: 2.51 hours\tBatch: 2/147\tEpoch: 5/6\tTraining Loss: 0.2225\n",
      "Elapsed time: 2.51 hours\tBatch: 3/147\tEpoch: 5/6\tTraining Loss: 0.2315\n",
      "Elapsed time: 2.51 hours\tBatch: 4/147\tEpoch: 5/6\tTraining Loss: 0.2223\n",
      "Elapsed time: 2.52 hours\tBatch: 5/147\tEpoch: 5/6\tTraining Loss: 0.2157\n",
      "Elapsed time: 2.52 hours\tBatch: 6/147\tEpoch: 5/6\tTraining Loss: 0.2155\n",
      "Elapsed time: 2.52 hours\tBatch: 7/147\tEpoch: 5/6\tTraining Loss: 0.2403\n",
      "Elapsed time: 2.53 hours\tBatch: 8/147\tEpoch: 5/6\tTraining Loss: 0.2381\n",
      "Elapsed time: 2.53 hours\tBatch: 9/147\tEpoch: 5/6\tTraining Loss: 0.2217\n",
      "Elapsed time: 2.54 hours\tBatch: 10/147\tEpoch: 5/6\tTraining Loss: 0.2392\n",
      "Elapsed time: 2.54 hours\tBatch: 11/147\tEpoch: 5/6\tTraining Loss: 0.2150\n",
      "Elapsed time: 2.54 hours\tBatch: 12/147\tEpoch: 5/6\tTraining Loss: 0.1952\n",
      "Elapsed time: 2.55 hours\tBatch: 13/147\tEpoch: 5/6\tTraining Loss: 0.2022\n",
      "Elapsed time: 2.55 hours\tBatch: 14/147\tEpoch: 5/6\tTraining Loss: 0.2399\n",
      "Elapsed time: 2.55 hours\tBatch: 15/147\tEpoch: 5/6\tTraining Loss: 0.2437\n",
      "Elapsed time: 2.56 hours\tBatch: 16/147\tEpoch: 5/6\tTraining Loss: 0.2331\n",
      "Elapsed time: 2.56 hours\tBatch: 17/147\tEpoch: 5/6\tTraining Loss: 0.2312\n",
      "Elapsed time: 2.56 hours\tBatch: 18/147\tEpoch: 5/6\tTraining Loss: 0.1887\n",
      "Elapsed time: 2.57 hours\tBatch: 19/147\tEpoch: 5/6\tTraining Loss: 0.1984\n",
      "Elapsed time: 2.57 hours\tBatch: 20/147\tEpoch: 5/6\tTraining Loss: 0.2312\n",
      "Elapsed time: 2.57 hours\tBatch: 21/147\tEpoch: 5/6\tTraining Loss: 0.2447\n",
      "Elapsed time: 2.58 hours\tBatch: 22/147\tEpoch: 5/6\tTraining Loss: 0.2145\n",
      "Elapsed time: 2.58 hours\tBatch: 23/147\tEpoch: 5/6\tTraining Loss: 0.2222\n",
      "Elapsed time: 2.58 hours\tBatch: 24/147\tEpoch: 5/6\tTraining Loss: 0.1597\n",
      "Elapsed time: 2.59 hours\tBatch: 25/147\tEpoch: 5/6\tTraining Loss: 0.2423\n",
      "Elapsed time: 2.59 hours\tBatch: 26/147\tEpoch: 5/6\tTraining Loss: 0.2040\n",
      "Elapsed time: 2.60 hours\tBatch: 27/147\tEpoch: 5/6\tTraining Loss: 0.2463\n",
      "Elapsed time: 2.60 hours\tBatch: 28/147\tEpoch: 5/6\tTraining Loss: 0.2511\n",
      "Elapsed time: 2.60 hours\tBatch: 29/147\tEpoch: 5/6\tTraining Loss: 0.2286\n",
      "Elapsed time: 2.61 hours\tBatch: 30/147\tEpoch: 5/6\tTraining Loss: 0.1876\n",
      "Elapsed time: 2.61 hours\tBatch: 31/147\tEpoch: 5/6\tTraining Loss: 0.2204\n",
      "Elapsed time: 2.61 hours\tBatch: 32/147\tEpoch: 5/6\tTraining Loss: 0.2221\n",
      "Elapsed time: 2.62 hours\tBatch: 33/147\tEpoch: 5/6\tTraining Loss: 0.2084\n",
      "Elapsed time: 2.62 hours\tBatch: 34/147\tEpoch: 5/6\tTraining Loss: 0.2332\n",
      "Elapsed time: 2.62 hours\tBatch: 35/147\tEpoch: 5/6\tTraining Loss: 0.2099\n",
      "Elapsed time: 2.63 hours\tBatch: 36/147\tEpoch: 5/6\tTraining Loss: 0.2155\n",
      "Elapsed time: 2.63 hours\tBatch: 37/147\tEpoch: 5/6\tTraining Loss: 0.2366\n",
      "Elapsed time: 2.63 hours\tBatch: 38/147\tEpoch: 5/6\tTraining Loss: 0.1887\n",
      "Elapsed time: 2.64 hours\tBatch: 39/147\tEpoch: 5/6\tTraining Loss: 0.2388\n",
      "Elapsed time: 2.64 hours\tBatch: 40/147\tEpoch: 5/6\tTraining Loss: 0.2083\n",
      "Elapsed time: 2.64 hours\tBatch: 41/147\tEpoch: 5/6\tTraining Loss: 0.1941\n",
      "Elapsed time: 2.65 hours\tBatch: 42/147\tEpoch: 5/6\tTraining Loss: 0.2224\n",
      "Elapsed time: 2.65 hours\tBatch: 43/147\tEpoch: 5/6\tTraining Loss: 0.2032\n",
      "Elapsed time: 2.65 hours\tBatch: 44/147\tEpoch: 5/6\tTraining Loss: 0.2152\n",
      "Elapsed time: 2.66 hours\tBatch: 45/147\tEpoch: 5/6\tTraining Loss: 0.2598\n",
      "Elapsed time: 2.66 hours\tBatch: 46/147\tEpoch: 5/6\tTraining Loss: 0.2531\n",
      "Elapsed time: 2.66 hours\tBatch: 47/147\tEpoch: 5/6\tTraining Loss: 0.2176\n",
      "Elapsed time: 2.67 hours\tBatch: 48/147\tEpoch: 5/6\tTraining Loss: 0.2190\n",
      "Elapsed time: 2.67 hours\tBatch: 49/147\tEpoch: 5/6\tTraining Loss: 0.2411\n",
      "Elapsed time: 2.67 hours\tBatch: 50/147\tEpoch: 5/6\tTraining Loss: 0.2072\n",
      "Elapsed time: 2.68 hours\tBatch: 51/147\tEpoch: 5/6\tTraining Loss: 0.2020\n",
      "Elapsed time: 2.68 hours\tBatch: 52/147\tEpoch: 5/6\tTraining Loss: 0.2554\n",
      "Elapsed time: 2.68 hours\tBatch: 53/147\tEpoch: 5/6\tTraining Loss: 0.2332\n",
      "Elapsed time: 2.69 hours\tBatch: 54/147\tEpoch: 5/6\tTraining Loss: 0.2708\n",
      "Elapsed time: 2.69 hours\tBatch: 55/147\tEpoch: 5/6\tTraining Loss: 0.2007\n",
      "Elapsed time: 2.69 hours\tBatch: 56/147\tEpoch: 5/6\tTraining Loss: 0.2333\n",
      "Elapsed time: 2.70 hours\tBatch: 57/147\tEpoch: 5/6\tTraining Loss: 0.2321\n",
      "Elapsed time: 2.70 hours\tBatch: 58/147\tEpoch: 5/6\tTraining Loss: 0.2351\n",
      "Elapsed time: 2.70 hours\tBatch: 59/147\tEpoch: 5/6\tTraining Loss: 0.2282\n",
      "Elapsed time: 2.71 hours\tBatch: 60/147\tEpoch: 5/6\tTraining Loss: 0.1920\n",
      "Elapsed time: 2.71 hours\tBatch: 61/147\tEpoch: 5/6\tTraining Loss: 0.2188\n",
      "Elapsed time: 2.71 hours\tBatch: 62/147\tEpoch: 5/6\tTraining Loss: 0.2366\n",
      "Elapsed time: 2.72 hours\tBatch: 63/147\tEpoch: 5/6\tTraining Loss: 0.2432\n",
      "Elapsed time: 2.72 hours\tBatch: 64/147\tEpoch: 5/6\tTraining Loss: 0.2058\n",
      "Elapsed time: 2.72 hours\tBatch: 65/147\tEpoch: 5/6\tTraining Loss: 0.1926\n",
      "Elapsed time: 2.73 hours\tBatch: 66/147\tEpoch: 5/6\tTraining Loss: 0.1960\n",
      "Elapsed time: 2.73 hours\tBatch: 67/147\tEpoch: 5/6\tTraining Loss: 0.2444\n",
      "Elapsed time: 2.73 hours\tBatch: 68/147\tEpoch: 5/6\tTraining Loss: 0.2174\n",
      "Elapsed time: 2.74 hours\tBatch: 69/147\tEpoch: 5/6\tTraining Loss: 0.1974\n",
      "Elapsed time: 2.74 hours\tBatch: 70/147\tEpoch: 5/6\tTraining Loss: 0.2177\n",
      "Elapsed time: 2.74 hours\tBatch: 71/147\tEpoch: 5/6\tTraining Loss: 0.1984\n",
      "Elapsed time: 2.75 hours\tBatch: 72/147\tEpoch: 5/6\tTraining Loss: 0.2459\n",
      "Elapsed time: 2.75 hours\tBatch: 73/147\tEpoch: 5/6\tTraining Loss: 0.2094\n",
      "Elapsed time: 2.75 hours\tBatch: 74/147\tEpoch: 5/6\tTraining Loss: 0.2229\n",
      "Elapsed time: 2.76 hours\tBatch: 75/147\tEpoch: 5/6\tTraining Loss: 0.2140\n",
      "Elapsed time: 2.76 hours\tBatch: 76/147\tEpoch: 5/6\tTraining Loss: 0.2214\n",
      "Elapsed time: 2.76 hours\tBatch: 77/147\tEpoch: 5/6\tTraining Loss: 0.2407\n",
      "Elapsed time: 2.77 hours\tBatch: 78/147\tEpoch: 5/6\tTraining Loss: 0.2379\n",
      "Elapsed time: 2.77 hours\tBatch: 79/147\tEpoch: 5/6\tTraining Loss: 0.1996\n",
      "Elapsed time: 2.77 hours\tBatch: 80/147\tEpoch: 5/6\tTraining Loss: 0.2767\n",
      "Elapsed time: 2.78 hours\tBatch: 81/147\tEpoch: 5/6\tTraining Loss: 0.2320\n",
      "Elapsed time: 2.78 hours\tBatch: 82/147\tEpoch: 5/6\tTraining Loss: 0.2062\n",
      "Elapsed time: 2.78 hours\tBatch: 83/147\tEpoch: 5/6\tTraining Loss: 0.2128\n",
      "Elapsed time: 2.79 hours\tBatch: 84/147\tEpoch: 5/6\tTraining Loss: 0.2121\n",
      "Elapsed time: 2.79 hours\tBatch: 85/147\tEpoch: 5/6\tTraining Loss: 0.2178\n",
      "Elapsed time: 2.79 hours\tBatch: 86/147\tEpoch: 5/6\tTraining Loss: 0.2431\n",
      "Elapsed time: 2.80 hours\tBatch: 87/147\tEpoch: 5/6\tTraining Loss: 0.2171\n",
      "Elapsed time: 2.80 hours\tBatch: 88/147\tEpoch: 5/6\tTraining Loss: 0.1984\n",
      "Elapsed time: 2.80 hours\tBatch: 89/147\tEpoch: 5/6\tTraining Loss: 0.2267\n",
      "Elapsed time: 2.81 hours\tBatch: 90/147\tEpoch: 5/6\tTraining Loss: 0.2527\n",
      "Elapsed time: 2.81 hours\tBatch: 91/147\tEpoch: 5/6\tTraining Loss: 0.2790\n",
      "Elapsed time: 2.81 hours\tBatch: 92/147\tEpoch: 5/6\tTraining Loss: 0.2167\n",
      "Elapsed time: 2.82 hours\tBatch: 93/147\tEpoch: 5/6\tTraining Loss: 0.2172\n",
      "Elapsed time: 2.82 hours\tBatch: 94/147\tEpoch: 5/6\tTraining Loss: 0.2648\n",
      "Elapsed time: 2.82 hours\tBatch: 95/147\tEpoch: 5/6\tTraining Loss: 0.2415\n",
      "Elapsed time: 2.83 hours\tBatch: 96/147\tEpoch: 5/6\tTraining Loss: 0.1993\n",
      "Elapsed time: 2.83 hours\tBatch: 97/147\tEpoch: 5/6\tTraining Loss: 0.2312\n",
      "Elapsed time: 2.83 hours\tBatch: 98/147\tEpoch: 5/6\tTraining Loss: 0.2231\n",
      "Elapsed time: 2.84 hours\tBatch: 99/147\tEpoch: 5/6\tTraining Loss: 0.2184\n",
      "Elapsed time: 2.84 hours\tBatch: 100/147\tEpoch: 5/6\tTraining Loss: 0.2264\n",
      "Elapsed time: 2.84 hours\tBatch: 101/147\tEpoch: 5/6\tTraining Loss: 0.2288\n",
      "Elapsed time: 2.85 hours\tBatch: 102/147\tEpoch: 5/6\tTraining Loss: 0.2350\n",
      "Elapsed time: 2.85 hours\tBatch: 103/147\tEpoch: 5/6\tTraining Loss: 0.2149\n",
      "Elapsed time: 2.85 hours\tBatch: 104/147\tEpoch: 5/6\tTraining Loss: 0.2482\n",
      "Elapsed time: 2.86 hours\tBatch: 105/147\tEpoch: 5/6\tTraining Loss: 0.2055\n",
      "Elapsed time: 2.86 hours\tBatch: 106/147\tEpoch: 5/6\tTraining Loss: 0.2012\n",
      "Elapsed time: 2.86 hours\tBatch: 107/147\tEpoch: 5/6\tTraining Loss: 0.2162\n",
      "Elapsed time: 2.87 hours\tBatch: 108/147\tEpoch: 5/6\tTraining Loss: 0.2366\n",
      "Elapsed time: 2.87 hours\tBatch: 109/147\tEpoch: 5/6\tTraining Loss: 0.2663\n",
      "Elapsed time: 2.87 hours\tBatch: 110/147\tEpoch: 5/6\tTraining Loss: 0.2244\n",
      "Elapsed time: 2.88 hours\tBatch: 111/147\tEpoch: 5/6\tTraining Loss: 0.2314\n",
      "Elapsed time: 2.88 hours\tBatch: 112/147\tEpoch: 5/6\tTraining Loss: 0.2080\n",
      "Elapsed time: 2.88 hours\tBatch: 113/147\tEpoch: 5/6\tTraining Loss: 0.2168\n",
      "Elapsed time: 2.89 hours\tBatch: 114/147\tEpoch: 5/6\tTraining Loss: 0.2172\n",
      "Elapsed time: 2.89 hours\tBatch: 115/147\tEpoch: 5/6\tTraining Loss: 0.2196\n",
      "Elapsed time: 2.89 hours\tBatch: 116/147\tEpoch: 5/6\tTraining Loss: 0.2401\n",
      "Elapsed time: 2.90 hours\tBatch: 117/147\tEpoch: 5/6\tTraining Loss: 0.2552\n",
      "Elapsed time: 2.90 hours\tBatch: 118/147\tEpoch: 5/6\tTraining Loss: 0.2259\n",
      "Elapsed time: 2.90 hours\tBatch: 119/147\tEpoch: 5/6\tTraining Loss: 0.2075\n",
      "Elapsed time: 2.91 hours\tBatch: 120/147\tEpoch: 5/6\tTraining Loss: 0.2477\n",
      "Elapsed time: 2.91 hours\tBatch: 121/147\tEpoch: 5/6\tTraining Loss: 0.2015\n",
      "Elapsed time: 2.91 hours\tBatch: 122/147\tEpoch: 5/6\tTraining Loss: 0.2347\n",
      "Elapsed time: 2.92 hours\tBatch: 123/147\tEpoch: 5/6\tTraining Loss: 0.2132\n",
      "Elapsed time: 2.92 hours\tBatch: 124/147\tEpoch: 5/6\tTraining Loss: 0.2412\n",
      "Elapsed time: 2.92 hours\tBatch: 125/147\tEpoch: 5/6\tTraining Loss: 0.2114\n",
      "Elapsed time: 2.93 hours\tBatch: 126/147\tEpoch: 5/6\tTraining Loss: 0.2268\n",
      "Elapsed time: 2.93 hours\tBatch: 127/147\tEpoch: 5/6\tTraining Loss: 0.2174\n",
      "Elapsed time: 2.93 hours\tBatch: 128/147\tEpoch: 5/6\tTraining Loss: 0.2202\n",
      "Elapsed time: 2.94 hours\tBatch: 129/147\tEpoch: 5/6\tTraining Loss: 0.1999\n",
      "Elapsed time: 2.94 hours\tBatch: 130/147\tEpoch: 5/6\tTraining Loss: 0.2142\n",
      "Elapsed time: 2.94 hours\tBatch: 131/147\tEpoch: 5/6\tTraining Loss: 0.2283\n",
      "Elapsed time: 2.95 hours\tBatch: 132/147\tEpoch: 5/6\tTraining Loss: 0.2204\n",
      "Elapsed time: 2.95 hours\tBatch: 133/147\tEpoch: 5/6\tTraining Loss: 0.2219\n",
      "Elapsed time: 2.95 hours\tBatch: 134/147\tEpoch: 5/6\tTraining Loss: 0.2289\n",
      "Elapsed time: 2.96 hours\tBatch: 135/147\tEpoch: 5/6\tTraining Loss: 0.2218\n",
      "Elapsed time: 2.96 hours\tBatch: 136/147\tEpoch: 5/6\tTraining Loss: 0.2068\n",
      "Elapsed time: 2.96 hours\tBatch: 137/147\tEpoch: 5/6\tTraining Loss: 0.2526\n",
      "Elapsed time: 2.97 hours\tBatch: 138/147\tEpoch: 5/6\tTraining Loss: 0.2207\n",
      "Elapsed time: 2.97 hours\tBatch: 139/147\tEpoch: 5/6\tTraining Loss: 0.2080\n",
      "Elapsed time: 2.97 hours\tBatch: 140/147\tEpoch: 5/6\tTraining Loss: 0.2254\n",
      "Elapsed time: 2.98 hours\tBatch: 141/147\tEpoch: 5/6\tTraining Loss: 0.2411\n",
      "Elapsed time: 2.98 hours\tBatch: 142/147\tEpoch: 5/6\tTraining Loss: 0.2547\n",
      "Elapsed time: 2.98 hours\tBatch: 143/147\tEpoch: 5/6\tTraining Loss: 0.2190\n",
      "Elapsed time: 2.99 hours\tBatch: 144/147\tEpoch: 5/6\tTraining Loss: 0.2278\n",
      "Elapsed time: 2.99 hours\tBatch: 145/147\tEpoch: 5/6\tTraining Loss: 0.2119\n",
      "Elapsed time: 2.99 hours\tBatch: 146/147\tEpoch: 5/6\tTraining Loss: 0.2018\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Validation loss for epoch 5: 0.1863\n",
      "Learning rate set to 1e-08\n",
      "Elapsed time: 3.12 hours\tBatch: 0/147\tEpoch: 6/6\tTraining Loss: 0.2426\n",
      "Elapsed time: 3.12 hours\tBatch: 1/147\tEpoch: 6/6\tTraining Loss: 0.2526\n",
      "Elapsed time: 3.13 hours\tBatch: 2/147\tEpoch: 6/6\tTraining Loss: 0.2081\n",
      "Elapsed time: 3.13 hours\tBatch: 3/147\tEpoch: 6/6\tTraining Loss: 0.2196\n",
      "Elapsed time: 3.13 hours\tBatch: 4/147\tEpoch: 6/6\tTraining Loss: 0.2453\n",
      "Elapsed time: 3.14 hours\tBatch: 5/147\tEpoch: 6/6\tTraining Loss: 0.1996\n",
      "Elapsed time: 3.14 hours\tBatch: 6/147\tEpoch: 6/6\tTraining Loss: 0.2384\n",
      "Elapsed time: 3.14 hours\tBatch: 7/147\tEpoch: 6/6\tTraining Loss: 0.2160\n",
      "Elapsed time: 3.15 hours\tBatch: 8/147\tEpoch: 6/6\tTraining Loss: 0.2053\n",
      "Elapsed time: 3.15 hours\tBatch: 9/147\tEpoch: 6/6\tTraining Loss: 0.2083\n",
      "Elapsed time: 3.15 hours\tBatch: 10/147\tEpoch: 6/6\tTraining Loss: 0.2228\n",
      "Elapsed time: 3.16 hours\tBatch: 11/147\tEpoch: 6/6\tTraining Loss: 0.1998\n",
      "Elapsed time: 3.16 hours\tBatch: 12/147\tEpoch: 6/6\tTraining Loss: 0.2274\n",
      "Elapsed time: 3.16 hours\tBatch: 13/147\tEpoch: 6/6\tTraining Loss: 0.2215\n",
      "Elapsed time: 3.17 hours\tBatch: 14/147\tEpoch: 6/6\tTraining Loss: 0.2099\n",
      "Elapsed time: 3.17 hours\tBatch: 15/147\tEpoch: 6/6\tTraining Loss: 0.2059\n",
      "Elapsed time: 3.17 hours\tBatch: 16/147\tEpoch: 6/6\tTraining Loss: 0.2737\n",
      "Elapsed time: 3.18 hours\tBatch: 17/147\tEpoch: 6/6\tTraining Loss: 0.2323\n",
      "Elapsed time: 3.18 hours\tBatch: 18/147\tEpoch: 6/6\tTraining Loss: 0.1974\n",
      "Elapsed time: 3.19 hours\tBatch: 19/147\tEpoch: 6/6\tTraining Loss: 0.2288\n",
      "Elapsed time: 3.19 hours\tBatch: 20/147\tEpoch: 6/6\tTraining Loss: 0.2280\n",
      "Elapsed time: 3.19 hours\tBatch: 21/147\tEpoch: 6/6\tTraining Loss: 0.2206\n",
      "Elapsed time: 3.20 hours\tBatch: 22/147\tEpoch: 6/6\tTraining Loss: 0.2221\n",
      "Elapsed time: 3.20 hours\tBatch: 23/147\tEpoch: 6/6\tTraining Loss: 0.2372\n",
      "Elapsed time: 3.20 hours\tBatch: 24/147\tEpoch: 6/6\tTraining Loss: 0.2255\n",
      "Elapsed time: 3.21 hours\tBatch: 25/147\tEpoch: 6/6\tTraining Loss: 0.2332\n",
      "Elapsed time: 3.21 hours\tBatch: 26/147\tEpoch: 6/6\tTraining Loss: 0.2244\n",
      "Elapsed time: 3.21 hours\tBatch: 27/147\tEpoch: 6/6\tTraining Loss: 0.2260\n",
      "Elapsed time: 3.22 hours\tBatch: 28/147\tEpoch: 6/6\tTraining Loss: 0.2196\n",
      "Elapsed time: 3.22 hours\tBatch: 29/147\tEpoch: 6/6\tTraining Loss: 0.2178\n",
      "Elapsed time: 3.22 hours\tBatch: 30/147\tEpoch: 6/6\tTraining Loss: 0.2082\n",
      "Elapsed time: 3.23 hours\tBatch: 31/147\tEpoch: 6/6\tTraining Loss: 0.2228\n",
      "Elapsed time: 3.23 hours\tBatch: 32/147\tEpoch: 6/6\tTraining Loss: 0.2245\n",
      "Elapsed time: 3.23 hours\tBatch: 33/147\tEpoch: 6/6\tTraining Loss: 0.2337\n",
      "Elapsed time: 3.24 hours\tBatch: 34/147\tEpoch: 6/6\tTraining Loss: 0.2082\n",
      "Elapsed time: 3.24 hours\tBatch: 35/147\tEpoch: 6/6\tTraining Loss: 0.2190\n",
      "Elapsed time: 3.24 hours\tBatch: 36/147\tEpoch: 6/6\tTraining Loss: 0.2189\n",
      "Elapsed time: 3.25 hours\tBatch: 37/147\tEpoch: 6/6\tTraining Loss: 0.2055\n",
      "Elapsed time: 3.25 hours\tBatch: 38/147\tEpoch: 6/6\tTraining Loss: 0.2419\n",
      "Elapsed time: 3.25 hours\tBatch: 39/147\tEpoch: 6/6\tTraining Loss: 0.2627\n",
      "Elapsed time: 3.26 hours\tBatch: 40/147\tEpoch: 6/6\tTraining Loss: 0.2188\n",
      "Elapsed time: 3.26 hours\tBatch: 41/147\tEpoch: 6/6\tTraining Loss: 0.2442\n",
      "Elapsed time: 3.26 hours\tBatch: 42/147\tEpoch: 6/6\tTraining Loss: 0.1940\n",
      "Elapsed time: 3.27 hours\tBatch: 43/147\tEpoch: 6/6\tTraining Loss: 0.2303\n",
      "Elapsed time: 3.27 hours\tBatch: 44/147\tEpoch: 6/6\tTraining Loss: 0.2668\n",
      "Elapsed time: 3.27 hours\tBatch: 45/147\tEpoch: 6/6\tTraining Loss: 0.2432\n",
      "Elapsed time: 3.28 hours\tBatch: 46/147\tEpoch: 6/6\tTraining Loss: 0.2329\n",
      "Elapsed time: 3.28 hours\tBatch: 47/147\tEpoch: 6/6\tTraining Loss: 0.2412\n",
      "Elapsed time: 3.28 hours\tBatch: 48/147\tEpoch: 6/6\tTraining Loss: 0.2163\n",
      "Elapsed time: 3.29 hours\tBatch: 49/147\tEpoch: 6/6\tTraining Loss: 0.2010\n",
      "Elapsed time: 3.29 hours\tBatch: 50/147\tEpoch: 6/6\tTraining Loss: 0.2162\n",
      "Elapsed time: 3.29 hours\tBatch: 51/147\tEpoch: 6/6\tTraining Loss: 0.2208\n",
      "Elapsed time: 3.30 hours\tBatch: 52/147\tEpoch: 6/6\tTraining Loss: 0.2585\n",
      "Elapsed time: 3.30 hours\tBatch: 53/147\tEpoch: 6/6\tTraining Loss: 0.2288\n",
      "Elapsed time: 3.30 hours\tBatch: 54/147\tEpoch: 6/6\tTraining Loss: 0.2083\n",
      "Elapsed time: 3.31 hours\tBatch: 55/147\tEpoch: 6/6\tTraining Loss: 0.2246\n",
      "Elapsed time: 3.31 hours\tBatch: 56/147\tEpoch: 6/6\tTraining Loss: 0.2176\n",
      "Elapsed time: 3.31 hours\tBatch: 57/147\tEpoch: 6/6\tTraining Loss: 0.2649\n",
      "Elapsed time: 3.32 hours\tBatch: 58/147\tEpoch: 6/6\tTraining Loss: 0.2642\n",
      "Elapsed time: 3.32 hours\tBatch: 59/147\tEpoch: 6/6\tTraining Loss: 0.2406\n",
      "Elapsed time: 3.32 hours\tBatch: 60/147\tEpoch: 6/6\tTraining Loss: 0.2118\n",
      "Elapsed time: 3.33 hours\tBatch: 61/147\tEpoch: 6/6\tTraining Loss: 0.2473\n",
      "Elapsed time: 3.33 hours\tBatch: 62/147\tEpoch: 6/6\tTraining Loss: 0.2578\n",
      "Elapsed time: 3.33 hours\tBatch: 63/147\tEpoch: 6/6\tTraining Loss: 0.2131\n",
      "Elapsed time: 3.34 hours\tBatch: 64/147\tEpoch: 6/6\tTraining Loss: 0.2353\n",
      "Elapsed time: 3.34 hours\tBatch: 65/147\tEpoch: 6/6\tTraining Loss: 0.1986\n",
      "Elapsed time: 3.34 hours\tBatch: 66/147\tEpoch: 6/6\tTraining Loss: 0.2222\n",
      "Elapsed time: 3.35 hours\tBatch: 67/147\tEpoch: 6/6\tTraining Loss: 0.2197\n",
      "Elapsed time: 3.35 hours\tBatch: 68/147\tEpoch: 6/6\tTraining Loss: 0.2439\n",
      "Elapsed time: 3.35 hours\tBatch: 69/147\tEpoch: 6/6\tTraining Loss: 0.2535\n",
      "Elapsed time: 3.36 hours\tBatch: 70/147\tEpoch: 6/6\tTraining Loss: 0.2210\n",
      "Elapsed time: 3.36 hours\tBatch: 71/147\tEpoch: 6/6\tTraining Loss: 0.2270\n",
      "Elapsed time: 3.36 hours\tBatch: 72/147\tEpoch: 6/6\tTraining Loss: 0.2148\n",
      "Elapsed time: 3.37 hours\tBatch: 73/147\tEpoch: 6/6\tTraining Loss: 0.2031\n",
      "Elapsed time: 3.37 hours\tBatch: 74/147\tEpoch: 6/6\tTraining Loss: 0.2138\n",
      "Elapsed time: 3.37 hours\tBatch: 75/147\tEpoch: 6/6\tTraining Loss: 0.2043\n",
      "Elapsed time: 3.38 hours\tBatch: 76/147\tEpoch: 6/6\tTraining Loss: 0.2551\n",
      "Elapsed time: 3.38 hours\tBatch: 77/147\tEpoch: 6/6\tTraining Loss: 0.2056\n",
      "Elapsed time: 3.38 hours\tBatch: 78/147\tEpoch: 6/6\tTraining Loss: 0.2203\n",
      "Elapsed time: 3.39 hours\tBatch: 79/147\tEpoch: 6/6\tTraining Loss: 0.2381\n",
      "Elapsed time: 3.39 hours\tBatch: 80/147\tEpoch: 6/6\tTraining Loss: 0.2227\n",
      "Elapsed time: 3.39 hours\tBatch: 81/147\tEpoch: 6/6\tTraining Loss: 0.1817\n",
      "Elapsed time: 3.40 hours\tBatch: 82/147\tEpoch: 6/6\tTraining Loss: 0.2444\n",
      "Elapsed time: 3.40 hours\tBatch: 83/147\tEpoch: 6/6\tTraining Loss: 0.2120\n",
      "Elapsed time: 3.40 hours\tBatch: 84/147\tEpoch: 6/6\tTraining Loss: 0.2457\n",
      "Elapsed time: 3.41 hours\tBatch: 85/147\tEpoch: 6/6\tTraining Loss: 0.2203\n",
      "Elapsed time: 3.41 hours\tBatch: 86/147\tEpoch: 6/6\tTraining Loss: 0.2280\n",
      "Elapsed time: 3.41 hours\tBatch: 87/147\tEpoch: 6/6\tTraining Loss: 0.2263\n",
      "Elapsed time: 3.42 hours\tBatch: 88/147\tEpoch: 6/6\tTraining Loss: 0.1948\n",
      "Elapsed time: 3.42 hours\tBatch: 89/147\tEpoch: 6/6\tTraining Loss: 0.2273\n",
      "Elapsed time: 3.42 hours\tBatch: 90/147\tEpoch: 6/6\tTraining Loss: 0.2391\n",
      "Elapsed time: 3.43 hours\tBatch: 91/147\tEpoch: 6/6\tTraining Loss: 0.2605\n",
      "Elapsed time: 3.43 hours\tBatch: 92/147\tEpoch: 6/6\tTraining Loss: 0.2510\n",
      "Elapsed time: 3.43 hours\tBatch: 93/147\tEpoch: 6/6\tTraining Loss: 0.2050\n",
      "Elapsed time: 3.44 hours\tBatch: 94/147\tEpoch: 6/6\tTraining Loss: 0.2301\n",
      "Elapsed time: 3.44 hours\tBatch: 95/147\tEpoch: 6/6\tTraining Loss: 0.2526\n",
      "Elapsed time: 3.44 hours\tBatch: 96/147\tEpoch: 6/6\tTraining Loss: 0.2257\n",
      "Elapsed time: 3.45 hours\tBatch: 97/147\tEpoch: 6/6\tTraining Loss: 0.2264\n",
      "Elapsed time: 3.45 hours\tBatch: 98/147\tEpoch: 6/6\tTraining Loss: 0.2025\n",
      "Elapsed time: 3.45 hours\tBatch: 99/147\tEpoch: 6/6\tTraining Loss: 0.2031\n",
      "Elapsed time: 3.46 hours\tBatch: 100/147\tEpoch: 6/6\tTraining Loss: 0.2458\n",
      "Elapsed time: 3.46 hours\tBatch: 101/147\tEpoch: 6/6\tTraining Loss: 0.2210\n",
      "Elapsed time: 3.46 hours\tBatch: 102/147\tEpoch: 6/6\tTraining Loss: 0.2173\n",
      "Elapsed time: 3.47 hours\tBatch: 103/147\tEpoch: 6/6\tTraining Loss: 0.1924\n",
      "Elapsed time: 3.47 hours\tBatch: 104/147\tEpoch: 6/6\tTraining Loss: 0.2105\n",
      "Elapsed time: 3.47 hours\tBatch: 105/147\tEpoch: 6/6\tTraining Loss: 0.2420\n",
      "Elapsed time: 3.48 hours\tBatch: 106/147\tEpoch: 6/6\tTraining Loss: 0.2098\n",
      "Elapsed time: 3.48 hours\tBatch: 107/147\tEpoch: 6/6\tTraining Loss: 0.1992\n",
      "Elapsed time: 3.48 hours\tBatch: 108/147\tEpoch: 6/6\tTraining Loss: 0.2472\n",
      "Elapsed time: 3.49 hours\tBatch: 109/147\tEpoch: 6/6\tTraining Loss: 0.2292\n",
      "Elapsed time: 3.49 hours\tBatch: 110/147\tEpoch: 6/6\tTraining Loss: 0.2169\n",
      "Elapsed time: 3.49 hours\tBatch: 111/147\tEpoch: 6/6\tTraining Loss: 0.1823\n",
      "Elapsed time: 3.50 hours\tBatch: 112/147\tEpoch: 6/6\tTraining Loss: 0.2362\n",
      "Elapsed time: 3.50 hours\tBatch: 113/147\tEpoch: 6/6\tTraining Loss: 0.2456\n",
      "Elapsed time: 3.50 hours\tBatch: 114/147\tEpoch: 6/6\tTraining Loss: 0.2365\n",
      "Elapsed time: 3.51 hours\tBatch: 115/147\tEpoch: 6/6\tTraining Loss: 0.2308\n",
      "Elapsed time: 3.51 hours\tBatch: 116/147\tEpoch: 6/6\tTraining Loss: 0.1948\n",
      "Elapsed time: 3.51 hours\tBatch: 117/147\tEpoch: 6/6\tTraining Loss: 0.2136\n",
      "Elapsed time: 3.52 hours\tBatch: 118/147\tEpoch: 6/6\tTraining Loss: 0.2437\n",
      "Elapsed time: 3.52 hours\tBatch: 119/147\tEpoch: 6/6\tTraining Loss: 0.2083\n",
      "Elapsed time: 3.52 hours\tBatch: 120/147\tEpoch: 6/6\tTraining Loss: 0.2158\n",
      "Elapsed time: 3.53 hours\tBatch: 121/147\tEpoch: 6/6\tTraining Loss: 0.2055\n",
      "Elapsed time: 3.53 hours\tBatch: 122/147\tEpoch: 6/6\tTraining Loss: 0.1877\n",
      "Elapsed time: 3.53 hours\tBatch: 123/147\tEpoch: 6/6\tTraining Loss: 0.2083\n",
      "Elapsed time: 3.54 hours\tBatch: 124/147\tEpoch: 6/6\tTraining Loss: 0.2272\n",
      "Elapsed time: 3.54 hours\tBatch: 125/147\tEpoch: 6/6\tTraining Loss: 0.2475\n",
      "Elapsed time: 3.54 hours\tBatch: 126/147\tEpoch: 6/6\tTraining Loss: 0.1807\n",
      "Elapsed time: 3.55 hours\tBatch: 127/147\tEpoch: 6/6\tTraining Loss: 0.1901\n",
      "Elapsed time: 3.55 hours\tBatch: 128/147\tEpoch: 6/6\tTraining Loss: 0.2436\n",
      "Elapsed time: 3.55 hours\tBatch: 129/147\tEpoch: 6/6\tTraining Loss: 0.2052\n",
      "Elapsed time: 3.56 hours\tBatch: 130/147\tEpoch: 6/6\tTraining Loss: 0.2015\n",
      "Elapsed time: 3.56 hours\tBatch: 131/147\tEpoch: 6/6\tTraining Loss: 0.2145\n",
      "Elapsed time: 3.56 hours\tBatch: 132/147\tEpoch: 6/6\tTraining Loss: 0.2120\n",
      "Elapsed time: 3.57 hours\tBatch: 133/147\tEpoch: 6/6\tTraining Loss: 0.1850\n",
      "Elapsed time: 3.57 hours\tBatch: 134/147\tEpoch: 6/6\tTraining Loss: 0.2175\n",
      "Elapsed time: 3.57 hours\tBatch: 135/147\tEpoch: 6/6\tTraining Loss: 0.2365\n",
      "Elapsed time: 3.58 hours\tBatch: 136/147\tEpoch: 6/6\tTraining Loss: 0.2460\n",
      "Elapsed time: 3.58 hours\tBatch: 137/147\tEpoch: 6/6\tTraining Loss: 0.2261\n",
      "Elapsed time: 3.58 hours\tBatch: 138/147\tEpoch: 6/6\tTraining Loss: 0.2210\n",
      "Elapsed time: 3.59 hours\tBatch: 139/147\tEpoch: 6/6\tTraining Loss: 0.2302\n",
      "Elapsed time: 3.59 hours\tBatch: 140/147\tEpoch: 6/6\tTraining Loss: 0.2316\n",
      "Elapsed time: 3.59 hours\tBatch: 141/147\tEpoch: 6/6\tTraining Loss: 0.2314\n",
      "Elapsed time: 3.60 hours\tBatch: 142/147\tEpoch: 6/6\tTraining Loss: 0.2444\n",
      "Elapsed time: 3.60 hours\tBatch: 143/147\tEpoch: 6/6\tTraining Loss: 0.2176\n",
      "Elapsed time: 3.60 hours\tBatch: 144/147\tEpoch: 6/6\tTraining Loss: 0.2421\n",
      "Elapsed time: 3.61 hours\tBatch: 145/147\tEpoch: 6/6\tTraining Loss: 0.2535\n",
      "Elapsed time: 3.61 hours\tBatch: 146/147\tEpoch: 6/6\tTraining Loss: 0.2185\n",
      "Validating...\n",
      "Iteration: 0/37\n",
      "Iteration: 1/37\n",
      "Iteration: 2/37\n",
      "Iteration: 3/37\n",
      "Iteration: 4/37\n",
      "Iteration: 5/37\n",
      "Iteration: 6/37\n",
      "Iteration: 7/37\n",
      "Iteration: 8/37\n",
      "Iteration: 9/37\n",
      "Iteration: 10/37\n",
      "Iteration: 11/37\n",
      "Iteration: 12/37\n",
      "Iteration: 13/37\n",
      "Iteration: 14/37\n",
      "Iteration: 15/37\n",
      "Iteration: 16/37\n",
      "Iteration: 17/37\n",
      "Iteration: 18/37\n",
      "Iteration: 19/37\n",
      "Iteration: 20/37\n",
      "Iteration: 21/37\n",
      "Iteration: 22/37\n",
      "Iteration: 23/37\n",
      "Iteration: 24/37\n",
      "Iteration: 25/37\n",
      "Iteration: 26/37\n",
      "Iteration: 27/37\n",
      "Iteration: 28/37\n",
      "Iteration: 29/37\n",
      "Iteration: 30/37\n",
      "Iteration: 31/37\n",
      "Iteration: 32/37\n",
      "Iteration: 33/37\n",
      "Iteration: 34/37\n",
      "Iteration: 35/37\n",
      "Iteration: 36/37\n",
      "Validation loss for epoch 6: 0.1853\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, training_loss, validation_loss = train_loop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:21:54.598806Z",
     "iopub.status.busy": "2020-08-21T15:21:54.598137Z",
     "iopub.status.idle": "2020-08-21T15:21:55.279750Z",
     "shell.execute_reply": "2020-08-21T15:21:55.280218Z"
    },
    "papermill": {
     "duration": 0.77268,
     "end_time": "2020-08-21T15:21:55.280351",
     "exception": false,
     "start_time": "2020-08-21T15:21:54.507671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib._color_data as mcd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "c1 = mcd.XKCD_COLORS[\"xkcd:\" + \"lavender\"].upper()\n",
    "c2 = mcd.XKCD_COLORS[\"xkcd:\" + \"lightblue\"].upper()\n",
    "c3 = mcd.XKCD_COLORS[\"xkcd:\" + \"aqua\"].upper()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "ax[0].plot(training_loss, color=c1)\n",
    "ax[0].set_title(f'Training Loss', fontsize=15)\n",
    "ax[0].grid()\n",
    "ax[0].set_ylabel('$\\mathcal{L}$', fontsize=16)\n",
    "ax[0].set_xlabel('Batch Iteration', fontsize=16)\n",
    "\n",
    "\n",
    "ax[1].plot(validation_loss, color=c2)\n",
    "ax[1].set_title(f'Validation Loss', fontsize=15)\n",
    "ax[1].grid()\n",
    "ax[1].set_ylabel('$\\mathcal{L}$', fontsize=16)\n",
    "ax[1].set_xlabel('Epoch Iteration', fontsize=16)\n",
    "\n",
    "\n",
    "fig.suptitle('Process of the weighted NAE loss', fontsize=18)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:21:55.432051Z",
     "iopub.status.busy": "2020-08-21T15:21:55.431213Z",
     "iopub.status.idle": "2020-08-21T15:21:55.436157Z",
     "shell.execute_reply": "2020-08-21T15:21:55.435682Z"
    },
    "papermill": {
     "duration": 0.081097,
     "end_time": "2020-08-21T15:21:55.436259",
     "exception": false,
     "start_time": "2020-08-21T15:21:55.355162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:21:55.584226Z",
     "iopub.status.busy": "2020-08-21T15:21:55.583420Z",
     "iopub.status.idle": "2020-08-21T15:56:08.353256Z",
     "shell.execute_reply": "2020-08-21T15:56:08.353842Z"
    },
    "papermill": {
     "duration": 2052.847234,
     "end_time": "2020-08-21T15:56:08.354050",
     "exception": false,
     "start_time": "2020-08-21T15:21:55.506816",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test data...\n",
      "Iteration nr: 0/184\n",
      "Iteration nr: 1/184\n",
      "Iteration nr: 2/184\n",
      "Iteration nr: 3/184\n",
      "Iteration nr: 4/184\n",
      "Iteration nr: 5/184\n",
      "Iteration nr: 6/184\n",
      "Iteration nr: 7/184\n",
      "Iteration nr: 8/184\n",
      "Iteration nr: 9/184\n",
      "Iteration nr: 10/184\n",
      "Iteration nr: 11/184\n",
      "Iteration nr: 12/184\n",
      "Iteration nr: 13/184\n",
      "Iteration nr: 14/184\n",
      "Iteration nr: 15/184\n",
      "Iteration nr: 16/184\n",
      "Iteration nr: 17/184\n",
      "Iteration nr: 18/184\n",
      "Iteration nr: 19/184\n",
      "Iteration nr: 20/184\n",
      "Iteration nr: 21/184\n",
      "Iteration nr: 22/184\n",
      "Iteration nr: 23/184\n",
      "Iteration nr: 24/184\n",
      "Iteration nr: 25/184\n",
      "Iteration nr: 26/184\n",
      "Iteration nr: 27/184\n",
      "Iteration nr: 28/184\n",
      "Iteration nr: 29/184\n",
      "Iteration nr: 30/184\n",
      "Iteration nr: 31/184\n",
      "Iteration nr: 32/184\n",
      "Iteration nr: 33/184\n",
      "Iteration nr: 34/184\n",
      "Iteration nr: 35/184\n",
      "Iteration nr: 36/184\n",
      "Iteration nr: 37/184\n",
      "Iteration nr: 38/184\n",
      "Iteration nr: 39/184\n",
      "Iteration nr: 40/184\n",
      "Iteration nr: 41/184\n",
      "Iteration nr: 42/184\n",
      "Iteration nr: 43/184\n",
      "Iteration nr: 44/184\n",
      "Iteration nr: 45/184\n",
      "Iteration nr: 46/184\n",
      "Iteration nr: 47/184\n",
      "Iteration nr: 48/184\n",
      "Iteration nr: 49/184\n",
      "Iteration nr: 50/184\n",
      "Iteration nr: 51/184\n",
      "Iteration nr: 52/184\n",
      "Iteration nr: 53/184\n",
      "Iteration nr: 54/184\n",
      "Iteration nr: 55/184\n",
      "Iteration nr: 56/184\n",
      "Iteration nr: 57/184\n",
      "Iteration nr: 58/184\n",
      "Iteration nr: 59/184\n",
      "Iteration nr: 60/184\n",
      "Iteration nr: 61/184\n",
      "Iteration nr: 62/184\n",
      "Iteration nr: 63/184\n",
      "Iteration nr: 64/184\n",
      "Iteration nr: 65/184\n",
      "Iteration nr: 66/184\n",
      "Iteration nr: 67/184\n",
      "Iteration nr: 68/184\n",
      "Iteration nr: 69/184\n",
      "Iteration nr: 70/184\n",
      "Iteration nr: 71/184\n",
      "Iteration nr: 72/184\n",
      "Iteration nr: 73/184\n",
      "Iteration nr: 74/184\n",
      "Iteration nr: 75/184\n",
      "Iteration nr: 76/184\n",
      "Iteration nr: 77/184\n",
      "Iteration nr: 78/184\n",
      "Iteration nr: 79/184\n",
      "Iteration nr: 80/184\n",
      "Iteration nr: 81/184\n",
      "Iteration nr: 82/184\n",
      "Iteration nr: 83/184\n",
      "Iteration nr: 84/184\n",
      "Iteration nr: 85/184\n",
      "Iteration nr: 86/184\n",
      "Iteration nr: 87/184\n",
      "Iteration nr: 88/184\n",
      "Iteration nr: 89/184\n",
      "Iteration nr: 90/184\n",
      "Iteration nr: 91/184\n",
      "Iteration nr: 92/184\n",
      "Iteration nr: 93/184\n",
      "Iteration nr: 94/184\n",
      "Iteration nr: 95/184\n",
      "Iteration nr: 96/184\n",
      "Iteration nr: 97/184\n",
      "Iteration nr: 98/184\n",
      "Iteration nr: 99/184\n",
      "Iteration nr: 100/184\n",
      "Iteration nr: 101/184\n",
      "Iteration nr: 102/184\n",
      "Iteration nr: 103/184\n",
      "Iteration nr: 104/184\n",
      "Iteration nr: 105/184\n",
      "Iteration nr: 106/184\n",
      "Iteration nr: 107/184\n",
      "Iteration nr: 108/184\n",
      "Iteration nr: 109/184\n",
      "Iteration nr: 110/184\n",
      "Iteration nr: 111/184\n",
      "Iteration nr: 112/184\n",
      "Iteration nr: 113/184\n",
      "Iteration nr: 114/184\n",
      "Iteration nr: 115/184\n",
      "Iteration nr: 116/184\n",
      "Iteration nr: 117/184\n",
      "Iteration nr: 118/184\n",
      "Iteration nr: 119/184\n",
      "Iteration nr: 120/184\n",
      "Iteration nr: 121/184\n",
      "Iteration nr: 122/184\n",
      "Iteration nr: 123/184\n",
      "Iteration nr: 124/184\n",
      "Iteration nr: 125/184\n",
      "Iteration nr: 126/184\n",
      "Iteration nr: 127/184\n",
      "Iteration nr: 128/184\n",
      "Iteration nr: 129/184\n",
      "Iteration nr: 130/184\n",
      "Iteration nr: 131/184\n",
      "Iteration nr: 132/184\n",
      "Iteration nr: 133/184\n",
      "Iteration nr: 134/184\n",
      "Iteration nr: 135/184\n",
      "Iteration nr: 136/184\n",
      "Iteration nr: 137/184\n",
      "Iteration nr: 138/184\n",
      "Iteration nr: 139/184\n",
      "Iteration nr: 140/184\n",
      "Iteration nr: 141/184\n",
      "Iteration nr: 142/184\n",
      "Iteration nr: 143/184\n",
      "Iteration nr: 144/184\n",
      "Iteration nr: 145/184\n",
      "Iteration nr: 146/184\n",
      "Iteration nr: 147/184\n",
      "Iteration nr: 148/184\n",
      "Iteration nr: 149/184\n",
      "Iteration nr: 150/184\n",
      "Iteration nr: 151/184\n",
      "Iteration nr: 152/184\n",
      "Iteration nr: 153/184\n",
      "Iteration nr: 154/184\n",
      "Iteration nr: 155/184\n",
      "Iteration nr: 156/184\n",
      "Iteration nr: 157/184\n",
      "Iteration nr: 158/184\n",
      "Iteration nr: 159/184\n",
      "Iteration nr: 160/184\n",
      "Iteration nr: 161/184\n",
      "Iteration nr: 162/184\n",
      "Iteration nr: 163/184\n",
      "Iteration nr: 164/184\n",
      "Iteration nr: 165/184\n",
      "Iteration nr: 166/184\n",
      "Iteration nr: 167/184\n",
      "Iteration nr: 168/184\n",
      "Iteration nr: 169/184\n",
      "Iteration nr: 170/184\n",
      "Iteration nr: 171/184\n",
      "Iteration nr: 172/184\n",
      "Iteration nr: 173/184\n",
      "Iteration nr: 174/184\n",
      "Iteration nr: 175/184\n",
      "Iteration nr: 176/184\n",
      "Iteration nr: 177/184\n",
      "Iteration nr: 178/184\n",
      "Iteration nr: 179/184\n",
      "Iteration nr: 180/184\n",
      "Iteration nr: 181/184\n",
      "Iteration nr: 182/184\n",
      "Iteration nr: 183/184\n",
      "CPU times: user 29min 41s, sys: 1min 54s, total: 31min 36s\n",
      "Wall time: 34min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_model = custom_resnet(False)\n",
    "try:\n",
    "    pred_model.load_state_dict(torch.load(config.save_path))\n",
    "except Exception as e:\n",
    "    print(f'Exception occured when trying to load model weights...\\n{e}')\n",
    "\n",
    "pred_model.eval()\n",
    "pred_model = pred_model.to(config.device)\n",
    "test_predictions = []\n",
    "print('Predicting test data...')\n",
    "for i, test_img in enumerate(test_loader):\n",
    "    print(f'Iteration nr: {i}/{len(test_loader)}')\n",
    "    test_img = test_img.to(config.device)\n",
    "    with torch.no_grad():\n",
    "        test_predictions.append(pred_model.forward(test_img))\n",
    "        \n",
    "\n",
    "avg_preds = []\n",
    "test_predictions = torch.cat(test_predictions, axis=0)\n",
    "for idx in range(0, len(test_predictions), 159):\n",
    "    avg_preds.append(test_predictions[idx:idx+159].mean(axis=0))\n",
    "\n",
    "preds =  torch.stack(avg_preds, axis=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:08.526434Z",
     "iopub.status.busy": "2020-08-21T15:56:08.525852Z",
     "iopub.status.idle": "2020-08-21T15:56:08.600166Z",
     "shell.execute_reply": "2020-08-21T15:56:08.600920Z"
    },
    "papermill": {
     "duration": 0.166037,
     "end_time": "2020-08-21T15:56:08.601100",
     "exception": false,
     "start_time": "2020-08-21T15:56:08.435063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([51.4418, 54.5243, 61.8456,  ..., 61.9911, 48.3727, 53.9399],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:08.772192Z",
     "iopub.status.busy": "2020-08-21T15:56:08.771337Z",
     "iopub.status.idle": "2020-08-21T15:56:08.775116Z",
     "shell.execute_reply": "2020-08-21T15:56:08.775596Z"
    },
    "papermill": {
     "duration": 0.094858,
     "end_time": "2020-08-21T15:56:08.775724",
     "exception": false,
     "start_time": "2020-08-21T15:56:08.680866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_predictions)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:08.948050Z",
     "iopub.status.busy": "2020-08-21T15:56:08.947267Z",
     "iopub.status.idle": "2020-08-21T15:56:08.951113Z",
     "shell.execute_reply": "2020-08-21T15:56:08.951675Z"
    },
    "papermill": {
     "duration": 0.096752,
     "end_time": "2020-08-21T15:56:08.951829",
     "exception": false,
     "start_time": "2020-08-21T15:56:08.855077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29385\n"
     ]
    }
   ],
   "source": [
    "print(len(submission_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:09.139696Z",
     "iopub.status.busy": "2020-08-21T15:56:09.138506Z",
     "iopub.status.idle": "2020-08-21T15:56:09.144175Z",
     "shell.execute_reply": "2020-08-21T15:56:09.143612Z"
    },
    "papermill": {
     "duration": 0.112092,
     "end_time": "2020-08-21T15:56:09.144284",
     "exception": false,
     "start_time": "2020-08-21T15:56:09.032192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003_age</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003_domain1_var1</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003_domain1_var2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003_domain2_var1</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_domain2_var2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Predicted\n",
       "0           10003_age       50.0\n",
       "1  10003_domain1_var1       50.0\n",
       "2  10003_domain1_var2       50.0\n",
       "3  10003_domain2_var1       50.0\n",
       "4  10003_domain2_var2       50.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:09.318851Z",
     "iopub.status.busy": "2020-08-21T15:56:09.318220Z",
     "iopub.status.idle": "2020-08-21T15:56:09.330317Z",
     "shell.execute_reply": "2020-08-21T15:56:09.329769Z"
    },
    "papermill": {
     "duration": 0.101387,
     "end_time": "2020-08-21T15:56:09.330419",
     "exception": false,
     "start_time": "2020-08-21T15:56:09.229032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_file.Predicted = test_predictions.flatten().cpu().numpy()*0.1276\n",
    "s = submission_file.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:09.494841Z",
     "iopub.status.busy": "2020-08-21T15:56:09.494203Z",
     "iopub.status.idle": "2020-08-21T15:56:10.008159Z",
     "shell.execute_reply": "2020-08-21T15:56:10.007200Z"
    },
    "papermill": {
     "duration": 0.598417,
     "end_time": "2020-08-21T15:56:10.008276",
     "exception": false,
     "start_time": "2020-08-21T15:56:09.409859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_file.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:10.187310Z",
     "iopub.status.busy": "2020-08-21T15:56:10.186561Z",
     "iopub.status.idle": "2020-08-21T15:56:10.190752Z",
     "shell.execute_reply": "2020-08-21T15:56:10.191412Z"
    },
    "papermill": {
     "duration": 0.097712,
     "end_time": "2020-08-21T15:56:10.191630",
     "exception": false,
     "start_time": "2020-08-21T15:56:10.093918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10003_age</td>\n",
       "      <td>6.563970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003_domain1_var1</td>\n",
       "      <td>6.957299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003_domain1_var2</td>\n",
       "      <td>7.891496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003_domain2_var1</td>\n",
       "      <td>6.148953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003_domain2_var2</td>\n",
       "      <td>6.851381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Predicted\n",
       "0           10003_age   6.563970\n",
       "1  10003_domain1_var1   6.957299\n",
       "2  10003_domain1_var2   7.891496\n",
       "3  10003_domain2_var1   6.148953\n",
       "4  10003_domain2_var2   6.851381"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:10.368265Z",
     "iopub.status.busy": "2020-08-21T15:56:10.367482Z",
     "iopub.status.idle": "2020-08-21T15:56:10.370885Z",
     "shell.execute_reply": "2020-08-21T15:56:10.370369Z"
    },
    "papermill": {
     "duration": 0.090383,
     "end_time": "2020-08-21T15:56:10.370984",
     "exception": false,
     "start_time": "2020-08-21T15:56:10.280601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.Predicted = test_predictions.flatten().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:10.603699Z",
     "iopub.status.busy": "2020-08-21T15:56:10.602953Z",
     "iopub.status.idle": "2020-08-21T15:56:10.606109Z",
     "shell.execute_reply": "2020-08-21T15:56:10.606573Z"
    },
    "papermill": {
     "duration": 0.154554,
     "end_time": "2020-08-21T15:56:10.606702",
     "exception": false,
     "start_time": "2020-08-21T15:56:10.452148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        51.441769\n",
       "1        54.524288\n",
       "2        61.845581\n",
       "3        48.189285\n",
       "4        53.694210\n",
       "           ...    \n",
       "29380    51.822346\n",
       "29381    54.814388\n",
       "29382    61.991089\n",
       "29383    48.372734\n",
       "29384    53.939896\n",
       "Name: Predicted, Length: 29385, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-21T15:56:10.809605Z",
     "iopub.status.busy": "2020-08-21T15:56:10.808741Z",
     "iopub.status.idle": "2020-08-21T15:56:10.973214Z",
     "shell.execute_reply": "2020-08-21T15:56:10.974431Z"
    },
    "papermill": {
     "duration": 0.284828,
     "end_time": "2020-08-21T15:56:10.974644",
     "exception": false,
     "start_time": "2020-08-21T15:56:10.689816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": 15477.034273,
   "end_time": "2020-08-21T15:56:13.203291",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-21T11:38:16.169018",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
